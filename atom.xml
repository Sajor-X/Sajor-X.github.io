<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Sajor's Blog]]></title>
  <link href="http://565785929.github.io/atom.xml" rel="self"/>
  <link href="http://565785929.github.io/"/>
  <updated>2021-09-17T15:43:32+08:00</updated>
  <id>http://565785929.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.coderforart.com/">CoderForArt</generator>

  
  <entry>
    <title type="html"><![CDATA[MySQL数据库设计规范（仅供参考）]]></title>
    <link href="http://565785929.github.io/16312407110535.html"/>
    <updated>2021-09-10T10:25:11+08:00</updated>
    <id>http://565785929.github.io/16312407110535.html</id>
    <content type="html"><![CDATA[
<p>目录<br/>
规范背景与目的<br/>
设计规范<br/>
2.1 数据库设计<br/>
2.1.1 库名<br/>
2.1.2 表结构<br/>
2.1.3 列数据类型优化<br/>
2.1.4 索引设计<br/>
2.1.5 分库分表、分区表<br/>
2.1.6 字符集<br/>
2.1.7 程序DAO层设计建议<br/>
2.1.8 一个规范的建表语句示例<br/>
2.2 SQL编写<br/>
2.2.1 DML语句<br/>
2.2.2 多表连接<br/>
2.2.3 事务<br/>
2.2.4 排序和分组<br/>
2.2.5 线上禁止使用的SQL语句</p>

<ol>
<li><p>规范背景与目的<br/>
MySQL数据库与 Oracle、 SQL Server 等数据库相比，有其内核上的优势与劣势。我们在使用MySQL数据库的时候需要遵循一定规范，扬长避短。本规范旨在帮助或指导RD、QA、OP等技术人员做出适合线上业务的数据库设计。在数据库变更和处理流程、数据库表设计、SQL编写等方面予以规范，从而为公司业务系统稳定、健康地运行提供保障。</p></li>
<li><p>设计规范<br/>
2.1 数据库设计<br/>
以下所有规范会按照【高危】、【强制】、【建议】三个级别进行标注，遵守优先级从高到低。</p></li>
</ol>

<p>对于不满足【高危】和【强制】两个级别的设计，DBA会强制打回要求修改。</p>

<p>2.1.1 库名<br/>
【强制】库的名称必须控制在32个字符以内，相关模块的表名与表名之间尽量提现join的关系，如user表和user_login表。<br/>
【强制】库的名称格式：业务系统名称_子系统名，同一模块使用的表名尽量使用统一前缀。<br/>
【强制】一般分库名称命名格式是库通配名_编号，编号从0开始递增，比如wenda_001以时间进行分库的名称格式是“库通配名_时间”<br/>
【强制】创建数据库时必须显式指定字符集，并且字符集只能是utf8或者utf8mb4。创建数据库SQL举例：create database db1 default character set utf8;。<br/>
2.1.2 表结构<br/>
【强制】表和列的名称必须控制在32个字符以内，表名只能使用字母、数字和下划线，一律小写。<br/>
【强制】表名要求模块名强相关，如师资系统采用”sz”作为前缀，渠道系统采用”qd”作为前缀等。<br/>
【强制】创建表时必须显式指定字符集为utf8或utf8mb4。<br/>
【强制】创建表时必须显式指定表存储引擎类型，如无特殊需求，一律为InnoDB。当需要使用除InnoDB/MyISAM/Memory以外的存储引擎时，必须通过DBA审核才能在生产环境中使用。因为Innodb表支持事务、行锁、宕机恢复、MVCC等关系型数据库重要特性，为业界使用最多的MySQL存储引擎。而这是其他大多数存储引擎不具备的，因此首推InnoDB。<br/>
【强制】建表必须有comment<br/>
【建议】建表时关于主键：(1)强制要求主键为id，类型为int或bigint，且为auto_increment(2)标识表里每一行主体的字段不要设为主键，建议设为其他字段如user_id，order_id等，并建立unique key索引（可参考cdb.teacher表设计）。因为如果设为主键且主键值为随机插入，则会导致innodb内部page分裂和大量随机I/O，性能下降。<br/>
【建议】核心表（如用户表，金钱相关的表）必须有行数据的创建时间字段create_time和最后更新时间字段update_time，便于查问题。<br/>
【建议】表中所有字段必须都是NOT NULL属性，业务可以根据需要定义DEFAULT值。因为使用NULL值会存在每一行都会占用额外存储空间、数据迁移容易出错、聚合函数计算结果偏差等问题。<br/>
【建议】建议对表里的blob、text等大字段，垂直拆分到其他表里，仅在需要读这些对象的时候才去select。<br/>
【建议】反范式设计：把经常需要join查询的字段，在其他表里冗余一份。如user_name属性在user_account，user_login_log等表里冗余一份，减少join查询。<br/>
【强制】中间表用于保留中间结果集，名称必须以tmp_开头。备份表用于备份或抓取源表快照，名称必须以bak_开头。中间表和备份表定期清理。<br/>
【强制】对于超过100W行的大表进行alter table，必须经过DBA审核，并在业务低峰期执行。因为alter table会产生表锁，期间阻塞对于该表的所有写入，对于业务可能会产生极大影响。<br/>
2.1.3 列数据类型优化<br/>
【建议】表中的自增列（auto_increment属性），推荐使用bigint类型。因为无符号int存储范围为-2147483648~2147483647（大约21亿左右），溢出后会导致报错。<br/>
【建议】业务中选择性很少的状态status、类型type等字段推荐使用tinytint或者smallint类型节省存储空间。<br/>
【建议】业务中IP地址字段推荐使用int类型，不推荐用char(15)。因为int只占4字节，可以用如下函数相互转换，而char(15)占用至少15字节。一旦表数据行数到了1亿，那么要多用1.1G存储空间。 SQL：select inet_aton(&#39;192.168.2.12&#39;); select inet_ntoa(3232236044); PHP: ip2long(‘192.168.2.12’); long2ip(3530427185);<br/>
【建议】不推荐使用enum，set。 因为它们浪费空间，且枚举值写死了，变更不方便。推荐使用tinyint或smallint。<br/>
【建议】不推荐使用blob，text等类型。它们都比较浪费硬盘和内存空间。在加载表数据时，会读取大字段到内存里从而浪费内存空间，影响系统性能。建议和PM、RD沟通，是否真的需要这么大字段。Innodb中当一行记录超过8098字节时，会将该记录中选取最长的一个字段将其768字节放在原始page里，该字段余下内容放在overflow-page里。不幸的是在compact行格式下，原始page和overflow-page都会加载。<br/>
【建议】存储金钱的字段，建议用int，程序端乘以100和除以100进行存取。因为int占用4字节，而double占用8字节，空间浪费。<br/>
【建议】文本数据尽量用varchar存储。因为varchar是变长存储，比char更省空间。MySQL server层规定一行所有文本最多存65535字节，因此在utf8字符集下最多存21844个字符，超过会自动转换为mediumtext字段。而text在utf8字符集下最多存21844个字符，mediumtext最多存2<sup>24/3个字符，longtext最多存2<sup>32个字符。一般建议用varchar类型，字符数不要超过2700。</sup></sup><br/>
【建议】时间类型尽量选取timestamp。因为datetime占用8字节，timestamp仅占用4字节，但是范围为1970-01-01 00:00:01到2038-01-01 00:00:00。更为高阶的方法，选用int来存储时间，使用SQL函数unix_timestamp()和from_unixtime()来进行转换。<br/>
2.1.4 索引设计<br/>
【强制】InnoDB表必须主键为id int/bigint auto_increment,且主键值禁止被更新。<br/>
【建议】主键的名称以“pk_”开头，唯一键以“uk_”或“uq_”开头，普通索引以“idx_”开头，一律使用小写格式，以表名/字段的名称或缩写作为后缀。<br/>
【强制】InnoDB和MyISAM存储引擎表，索引类型必须为BTREE；MEMORY表可以根据需要选择HASH或者BTREE类型索引。<br/>
【强制】单个索引中每个索引记录的长度不能超过64KB。<br/>
【建议】单个表上的索引个数不能超过7个。<br/>
【建议】在建立索引时，多考虑建立联合索引，并把区分度最高的字段放在最前面。如列userid的区分度可由select count(distinct userid)计算出来。<br/>
【建议】在多表join的SQL里，保证被驱动表的连接列上有索引，这样join执行效率最高。<br/>
【建议】建表或加索引时，保证表里互相不存在冗余索引。对于MySQL来说，如果表里已经存在key(a,b)，则key(a)为冗余索引，需要删除。<br/>
2.1.5 分库分表、分区表<br/>
【强制】分区表的分区字段（partition-key）必须有索引，或者是组合索引的首列。<br/>
【强制】单个分区表中的分区（包括子分区）个数不能超过1024。<br/>
【强制】上线前RD或者DBA必须指定分区表的创建、清理策略。<br/>
【强制】访问分区表的SQL必须包含分区键。<br/>
【建议】单个分区文件不超过2G，总大小不超过50G。建议总分区数不超过20个。<br/>
【强制】对于分区表执行alter table操作，必须在业务低峰期执行。<br/>
【强制】采用分库策略的，库的数量不能超过1024<br/>
【强制】采用分表策略的，表的数量不能超过4096<br/>
【建议】单个分表不超过500W行，ibd文件大小不超过2G，这样才能让数据分布式变得性能更佳。<br/>
【建议】水平分表尽量用取模方式，日志、报表类数据建议采用日期进行分表。<br/>
2.1.6 字符集<br/>
【强制】数据库本身库、表、列所有字符集必须保持一致，为utf8或utf8mb4。<br/>
【强制】前端程序字符集或者环境变量中的字符集，与数据库、表的字符集必须一致，统一为utf8。<br/>
2.1.7 程序层DAO设计建议<br/>
【建议】新的代码不要用model，推荐使用手动拼SQL+绑定变量传入参数的方式。因为model虽然可以使用面向对象的方式操作db，但是其使用不当很容易造成生成的SQL非常复杂，且model层自己做的强制类型转换性能较差，最终导致数据库性能下降。<br/>
【建议】前端程序连接MySQL或者redis，必须要有连接超时和失败重连机制，且失败重试必须有间隔时间。<br/>
【建议】前端程序报错里尽量能够提示MySQL或redis原生态的报错信息，便于排查错误。<br/>
【建议】对于有连接池的前端程序，必须根据业务需要配置初始、最小、最大连接数，超时时间以及连接回收机制，否则会耗尽数据库连接资源，造成线上事故。<br/>
【建议】对于log或history类型的表，随时间增长容易越来越大，因此上线前RD或者DBA必须建立表数据清理或归档方案。<br/>
【建议】在应用程序设计阶段，RD必须考虑并规避数据库中主从延迟对于业务的影响。尽量避免从库短时延迟（20秒以内）对业务造成影响，建议强制一致性的读开启事务走主库，或更新后过一段时间再去读从库。<br/>
【建议】多个并发业务逻辑访问同一块数据（innodb表）时，会在数据库端产生行锁甚至表锁导致并发下降，因此建议更新类SQL尽量基于主键去更新。<br/>
【建议】业务逻辑之间加锁顺序尽量保持一致，否则会导致死锁。<br/>
【建议】对于单表读写比大于10:1的数据行或单个列，可以将热点数据放在缓存里（如mecache或redis），加快访问速度，降低MySQL压力。<br/>
2.1.8 一个规范的建表语句示例<br/>
一个较为规范的建表语句为：</p>

<p>CREATE TABLE user (<br/>
  <code>id</code> bigint(11) NOT NULL AUTO_INCREMENT,<br/>
  <code>user_id</code> bigint(11) NOT NULL COMMENT ‘用户id’<br/>
  <code>username</code> varchar(45) NOT NULL COMMENT &#39;真实姓名&#39;,<br/>
  <code>email</code> varchar(30) NOT NULL COMMENT ‘用户邮箱’,<br/>
  <code>nickname</code> varchar(45) NOT NULL COMMENT &#39;昵称&#39;,<br/>
  <code>avatar</code> int(11) NOT NULL COMMENT &#39;头像&#39;,<br/>
  <code>birthday</code> date NOT NULL COMMENT &#39;生日&#39;,<br/>
  <code>sex</code> tinyint(4) DEFAULT &#39;0&#39; COMMENT &#39;性别&#39;,<br/>
  <code>short_introduce</code> varchar(150) DEFAULT NULL COMMENT &#39;一句话介绍自己，最多50个汉字&#39;,<br/>
  <code>user_resume</code> varchar(300) NOT NULL COMMENT &#39;用户提交的简历存放地址&#39;,<br/>
  <code>user_register_ip</code> int NOT NULL COMMENT ‘用户注册时的源ip’,<br/>
  <code>create_time</code> timestamp NOT NULL COMMENT ‘用户记录创建的时间’,<br/>
  <code>update_time</code> timestamp NOT NULL COMMENT ‘用户资料修改的时间’,<br/>
  <code>user_review_status</code> tinyint NOT NULL COMMENT ‘用户资料审核状态，1为通过，2为审核中，3为未通过，4为还未提交审核’,<br/>
  PRIMARY KEY (<code>id</code>),<br/>
  UNIQUE KEY <code>idx_user_id</code> (<code>user_id</code>),<br/>
  KEY <code>idx_username</code>(<code>username</code>),<br/>
  KEY <code>idx_create_time</code>(<code>create_time</code>,<code>user_review_status</code>)<br/>
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&#39;网站用户基本信息&#39;;<br/>
2.2 SQL编写<br/>
2.2.1 DML语句<br/>
【强制】SELECT语句必须指定具体字段名称，禁止写成*。因为select *会将不该读的数据也从MySQL里读出来，造成网卡压力。且表字段一旦更新，但model层没有来得及更新的话，系统会报错。<br/>
【强制】insert语句指定具体字段名称，不要写成insert into t1 values(…)，道理同上。<br/>
【建议】insert into…values(XX),(XX),(XX)…。这里XX的值不要超过5000个。值过多虽然上线很很快，但会引起主从同步延迟。<br/>
【建议】SELECT语句不要使用UNION，推荐使用UNION ALL，并且UNION子句个数限制在5个以内。因为union all不需要去重，节省数据库资源，提高性能。<br/>
【建议】in值列表限制在500以内。例如select… where userid in(….500个以内…)，这么做是为了减少底层扫描，减轻数据库压力从而加速查询。<br/>
【建议】事务里批量更新数据需要控制数量，进行必要的sleep，做到少量多次。<br/>
【强制】事务涉及的表必须全部是innodb表。否则一旦失败不会全部回滚，且易造成主从库同步终端。<br/>
【强制】写入和事务发往主库，只读SQL发往从库。<br/>
【强制】除静态表或小表（100行以内），DML语句必须有where条件，且使用索引查找。<br/>
【强制】生产环境禁止使用hint，如sql_no_cache，force index，ignore key，straight join等。因为hint是用来强制SQL按照某个执行计划来执行，但随着数据量变化我们无法保证自己当初的预判是正确的，因此我们要相信MySQL优化器！<br/>
【强制】where条件里等号左右字段类型必须一致，否则无法利用索引。<br/>
【建议】SELECT|UPDATE|DELETE|REPLACE要有WHERE子句，且WHERE子句的条件必需使用索引查找。<br/>
【强制】生产数据库中强烈不推荐大表上发生全表扫描，但对于100行以下的静态表可以全表扫描。查询数据量不要超过表行数的25%，否则不会利用索引。<br/>
【强制】WHERE 子句中禁止只使用全模糊的LIKE条件进行查找，必须有其他等值或范围查询条件，否则无法利用索引。<br/>
【建议】索引列不要使用函数或表达式，否则无法利用索引。如where length(name)=&#39;Admin&#39;或where user_id+2=10023。<br/>
【建议】减少使用or语句，可将or语句优化为union，然后在各个where条件上建立索引。如where a=1 or b=2优化为where a=1… union …where b=2, key(a),key(b)。<br/>
【建议】分页查询，当limit起点较高时，可先用过滤条件进行过滤。如select a,b,c from t1 limit 10000,20;优化为: select a,b,c from t1 where id&gt;10000 limit 20;。<br/>
2.2.2 多表连接<br/>
【强制】禁止跨db的join语句。因为这样可以减少模块间耦合，为数据库拆分奠定坚实基础。<br/>
【强制】禁止在业务的更新类SQL语句中使用join，比如update t1 join t2…。<br/>
【建议】不建议使用子查询，建议将子查询SQL拆开结合程序多次查询，或使用join来代替子查询。<br/>
【建议】线上环境，多表join不要超过3个表。<br/>
【建议】多表连接查询推荐使用别名，且SELECT列表中要用别名引用字段，数据库.表格式，如select a from db1.table1 alias1 where …。<br/>
【建议】在多表join中，尽量选取结果集较小的表作为驱动表，来join其他表。<br/>
2.2.3 事务<br/>
【建议】事务中INSERT|UPDATE|DELETE|REPLACE语句操作的行数控制在2000以内，以及WHERE子句中IN列表的传参个数控制在500以内。<br/>
【建议】批量操作数据时，需要控制事务处理间隔时间，进行必要的sleep，一般建议值5-10秒。<br/>
【建议】对于有auto_increment属性字段的表的插入操作，并发需要控制在200以内。<br/>
【强制】程序设计必须考虑“数据库事务隔离级别”带来的影响，包括脏读、不可重复读和幻读。线上建议事务隔离级别为repeatable-read。<br/>
【建议】事务里包含SQL不超过5个（支付业务除外）。因为过长的事务会导致锁数据较久，MySQL内部缓存、连接消耗过多等雪崩问题。<br/>
【建议】事务里更新语句尽量基于主键或unique key，如update … where id=XX; 否则会产生间隙锁，内部扩大锁定范围，导致系统性能下降，产生死锁。<br/>
【建议】尽量把一些典型外部调用移出事务，如调用webservice，访问文件存储等，从而避免事务过长。<br/>
【建议】对于MySQL主从延迟严格敏感的select语句，请开启事务强制访问主库。<br/>
2.2.4 排序和分组<br/>
【建议】减少使用order by，和业务沟通能不排序就不排序，或将排序放到程序端去做。order by、group by、distinct这些语句较为耗费CPU，数据库的CPU资源是极其宝贵的。<br/>
【建议】order by、group by、distinct这些SQL尽量利用索引直接检索出排序好的数据。如where a=1 order by可以利用key(a,b)。<br/>
【建议】包含了order by、group by、distinct这些查询的语句，where条件过滤出来的结果集请保持在1000行以内，否则SQL会很慢。<br/>
2.2.5 线上禁止使用的SQL语句<br/>
【高危】禁用update|delete t1 … where a=XX limit XX; 这种带limit的更新语句。因为会导致主从不一致，导致数据错乱。建议加上order by PK。<br/>
【高危】禁止使用关联子查询，如update t1 set … where name in(select name from user where…);效率极其低下。<br/>
【强制】禁用procedure、function、trigger、views、event、外键约束。因为他们消耗数据库资源，降低数据库实例可扩展性。推荐都在程序端实现。<br/>
【强制】禁用insert into …on duplicate key update…在高并发环境下，会造成主从不一致。<br/>
【强制】禁止联表更新语句，如update t1,t2 where t1.id=t2.id…。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[04 | 深入浅出索引（上）]]></title>
    <link href="http://565785929.github.io/16309452975279.html"/>
    <updated>2021-09-07T00:21:37+08:00</updated>
    <id>http://565785929.github.io/16309452975279.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">什么是索引</a>
</li>
<li>
<a href="#toc_1">索引的常见模型</a>
<ul>
<li>
<a href="#toc_2">哈希表 hash table</a>
</li>
<li>
<a href="#toc_3">有序数组</a>
</li>
</ul>
</li>
</ul>


<blockquote>
<p>来自MySQL实战45讲</p>
</blockquote>

<h2 id="toc_0">什么是索引</h2>

<p>索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。</p>

<p>一本500页的书，如果你想快速找到其中的某一个知识点，在不借助目录的情况下，那我估计你可得找一会儿。同样，对于数据库的表而言，索引其实就是它的“目录”。</p>

<h2 id="toc_1">索引的常见模型</h2>

<ul>
<li>哈希表</li>
<li>有序数组</li>
<li>搜索树</li>
</ul>

<h3 id="toc_2">哈希表 hash table</h3>

<p>哈希表是一种以键-值（key-value）存储数据的结构，我们只要输入待查找的值即key，就可以找到其对应的值即Value。哈希的思路很简单，把值放在数组里，用一个哈希函数把key换算成一个确定的位置，然后把value放在数组的这个位置。</p>

<p>不可避免地，多个key值经过哈希函数的换算，会出现同一个值的情况，这称为哈希碰撞。处理这种情况的一种方法是，拉出一个链表。</p>

<p>假设，你现在维护着一个身份证信息和姓名的表，需要根据身份证号查找对应的名字，这时对应的哈希索引的示意图如下所示：</p>

<p><img src="media/16309452975279/16309958323648.jpg" alt=""/></p>

<p>图中，User2和User4根据身份证号算出来的值都是N，但没关系，后面还跟了一个链表。假设，这时候你要查ID_card_n2对应的名字是什么，处理步骤就是：首先，将ID_card_n2通过哈希函数算出N；然后，按顺序遍历，找到User2。</p>

<p>需要注意的是，图中四个ID_card_n的值并不是递增的，这样做的好处是增加新的User时速度会很快，只需要往后追加。但缺点是，因为不是有序的，所以哈希索引做区间查询的速度是很慢的。</p>

<p>你可以设想下，如果你现在要找身份证号在[ID_card_X, ID_card_Y]这个区间的所有用户，就必须全部扫描一遍了。</p>

<p>所以，哈希表这种结构适用于只有等值查询的场景，比如Memcached及其他一些NoSQL引擎。</p>

<h3 id="toc_3">有序数组</h3>

<p>而有序数组在等值查询和范围查询场景中的性能就都非常优秀。还是上面这个根据身份证号查名字的例子，如果我们使用有序数组来实现的话，示意图如下所示：</p>

<p><img src="media/16309452975279/16310286123200.jpg" alt=""/></p>

<p><img src="media/16309452975279/B+Tree.png" alt="B+Tree"/></p>

<p><a href="https://www.cs.usfca.edu/%7Egalles/visualization/BPlusTree.html">数据结构</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[03 | 事务隔离：为什么你改了我还看不见？]]></title>
    <link href="http://565785929.github.io/16304224326131.html"/>
    <updated>2021-08-31T23:07:12+08:00</updated>
    <id>http://565785929.github.io/16304224326131.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">隔离性与隔离级别</a>
<ul>
<li>
<a href="#toc_1">脏读</a>
</li>
<li>
<a href="#toc_2">幻读</a>
</li>
<li>
<a href="#toc_3">不可重复读</a>
</li>
</ul>
</li>
<li>
<a href="#toc_4">SQL标准的事务隔离级别包括：</a>
</li>
<li>
<a href="#toc_5">案例</a>
</li>
<li>
<a href="#toc_6">事务隔离的实现</a>
<ul>
<li>
<a href="#toc_7">可重复读</a>
</li>
<li>
<a href="#toc_8">事务的启动方式</a>
</li>
</ul>
</li>
</ul>


<blockquote>
<p>来自MySQL实战45讲</p>
</blockquote>

<h2 id="toc_0">隔离性与隔离级别</h2>

<p>提到事务，你肯定会想到ACID：</p>

<ul>
<li>原子性（Atomicity）</li>
<li>一致性（Consistency）</li>
<li>隔离性（Isolation）</li>
<li>持久性（Durability）</li>
</ul>

<p>今天我们就来说说其中I，也就是“隔离性”。</p>

<p>当数据库上有多个事务同时执行的时候，就可能出现：</p>

<ul>
<li>脏读（dirty read）</li>
<li>不可重复读（non-repeatable read）</li>
<li>幻读（phantom read）</li>
</ul>

<p>等的问题，为了解决这些问题，就有了“隔离级别”的概念。</p>

<h3 id="toc_1">脏读</h3>

<p>所谓脏读是指一个事务中访问到了另外一个事务未提交的数据</p>

<table>
<thead>
<tr>
<th>事务 1</th>
<th>事务 2</th>
</tr>
</thead>

<tbody>
<tr>
<td>begin</td>
<td>begin</td>
</tr>
<tr>
<td></td>
<td>update table set age = 10 where id = 1;</td>
</tr>
<tr>
<td>select age from table where id = 1;</td>
<td></td>
</tr>
<tr>
<td>commit</td>
<td>rollback</td>
</tr>
</tbody>
</table>

<p>如果 会话2 更新 age 为 10，但是在 commit 之前，会话1 希望得到 age，那么会话1 获得的值就是更新前的值。或者如果会话2 更新了值但是执行了 rollback，而会话 1 拿到的仍是 10。这就是脏读。</p>

<h3 id="toc_2">幻读</h3>

<p>一个事务读取2次，得到的记录条数不一致：</p>

<table>
<thead>
<tr>
<th>事务1</th>
<th>事务2</th>
</tr>
</thead>

<tbody>
<tr>
<td>begin</td>
<td>begin</td>
</tr>
<tr>
<td>select age from table where id &gt; 2;</td>
<td></td>
</tr>
<tr>
<td></td>
<td>insert into table(id, age) values(5, 10);</td>
</tr>
<tr>
<td></td>
<td>commit</td>
</tr>
<tr>
<td>select age from table where id &gt; 2;</td>
<td></td>
</tr>
<tr>
<td>commit</td>
<td></td>
</tr>
</tbody>
</table>

<p>上图很明显的表示了这个情况，由于在会话 1 之间插入了一个新的值，所以得到的两次数据就不一样了。</p>

<h3 id="toc_3">不可重复读</h3>

<p>一个事务读取同一条记录2次，得到的结果不一致：</p>

<table>
<thead>
<tr>
<th>事务1</th>
<th>事务2</th>
</tr>
</thead>

<tbody>
<tr>
<td>begin</td>
<td>begin</td>
</tr>
<tr>
<td>select age from table where id = 1</td>
<td></td>
</tr>
<tr>
<td></td>
<td>update table set age = 10 where id = 1;</td>
</tr>
<tr>
<td></td>
<td>commit</td>
</tr>
<tr>
<td>select age from table where id = 1;</td>
<td></td>
</tr>
<tr>
<td>commit</td>
<td></td>
</tr>
</tbody>
</table>

<p>由于在读取中间变更了数据，所以会话 1 事务查询期间的得到的结果就不一样了。</p>

<p>解决方案也就是下文提到的四种隔离级别，他们可以最大程度避免以上三种情况的发生。</p>

<p>在谈隔离级别之前，你首先要知道，你隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点。</p>

<h2 id="toc_4">SQL标准的事务隔离级别包括：</h2>

<ul>
<li>读未提交（read uncommitted）是指，一个事务还没提交时，它做的变更就能被别的事务看到。</li>
<li>读提交（read committed）是指，一个事务提交之后，它做的变更才会被其他事务看到。Oracle数据库默认级别。</li>
<li>可重复读（repeatable read）是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。MySQL数据库默认级别。</li>
<li>串行化（serializable）是指，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。</li>
</ul>

<table>
<thead>
<tr>
<th>隔离级别</th>
<th>脏读</th>
<th>不可重复读</th>
<th>幻读</th>
</tr>
</thead>

<tbody>
<tr>
<td>读未提交(Read uncommitted)</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td>读已提交(Read committed)</td>
<td>×</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td>可重复读(Repeatable read)</td>
<td>×</td>
<td>×</td>
<td>✓</td>
</tr>
<tr>
<td>串行化(Serializable)</td>
<td>×</td>
<td>×</td>
<td>×</td>
</tr>
</tbody>
</table>

<h2 id="toc_5">案例</h2>

<p>用一个例子说明这几种隔离级别。假设数据表T中只有一列，其中一行的值为1，下面是按照时间顺序执行两个事务的行为。</p>

<blockquote>
<p>mysql&gt; create table T(c int) engine=InnoDB;<br/>
mysql&gt; insert into T(c) values(1);</p>
</blockquote>

<p><img src="media/16304224326131/16306006330934.jpg" alt=""/><br/>
我们来看看在不同的隔离级别下，事务A会有哪些不同的返回结果，也就是图里面V1、V2、V3的返回值分别是什么。</p>

<ul>
<li><strong>读未提交</strong>: 若隔离级别是“读未提交”， 则V1的值就是2。这时候事务B虽然还没有提交，但是结果已经被A看到了。因此，V2、V3也都是2。</li>
<li><strong>读提交</strong>: 若隔离级别是“读提交”，则V1是1，V2的值是2。事务B的更新在提交后才能被A看到。所以， V3的值也是2。</li>
<li><strong>可重复读</strong>: 若隔离级别是“可重复读”，则V1、V2是1，V3是2。之所以V2还是1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。</li>
<li><strong>串行化</strong>: 若隔离级别是“串行化”，则在事务B执行“将1改成2”的时候，会被锁住。直到事务A提交后，事务B才可以继续执行。所以从A的角度看， V1、V2值是1，V3的值是2。</li>
</ul>

<h2 id="toc_6">事务隔离的实现</h2>

<p>在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。</p>

<ul>
<li>在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。</li>
<li>在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。</li>
<li>这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；</li>
<li>而“串行化”隔离级别下直接用加锁的方式来避免并行访问。</li>
</ul>

<p>我们可以看到在不同的隔离级别下，数据库行为是有所不同的。Oracle数据库的默认隔离级别其实就是“读提交”，因此对于一些从Oracle迁移到MySQL的应用，为保证数据库隔离级别的一致，你一定要记得将MySQL的隔离级别设置为“读提交”。</p>

<p>配置的方式是，将启动参数transaction-isolation的值设置成READ-COMMITTED。你可以用show variables来查看当前的值。</p>

<pre class="line-numbers"><code class="language-sql">MySQL root@(none):(none)&gt; show variables like &#39;transaction_isolation&#39;;

+-----------------------+-----------------+
| Variable_name         | Value           |
+-----------------------+-----------------+
| transaction_isolation | REPEATABLE-READ |
+-----------------------+-----------------+
</code></pre>

<h3 id="toc_7">可重复读</h3>

<p>在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。</p>

<p>假设一个值从1被按顺序改成了2、3、4，在回滚日志里面就会有类似下面的记录。</p>

<p><img src="media/16304224326131/16309424534139.jpg" alt=""/></p>

<p>当前值是4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的read-view。如图中看到的，在视图A、B、C里面，这一个记录的值分别是1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于read-view A，要得到1，就必须将当前值依次执行图中所有的回滚操作得到。</p>

<p>同时你会发现，即使现在有另外一个事务正在将4改成5，这个事务跟read-view A、B、C对应的事务是不会冲突的。</p>

<p>你一定会问，回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。</p>

<p>什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的read-view的时候。</p>

<p>基于上面的说明，我们来讨论一下为什么建议你尽量不要使用长事务。</p>

<p>长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。</p>

<p>在MySQL 5.5及以前的版本，回滚日志是跟数据字典一起放在ibdata文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。我见过数据只有20GB，而回滚段有200GB的库。最终只好为了清理回滚段，重建整个库。</p>

<p>除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库，这个我们会在后面讲锁的时候展开。</p>

<h3 id="toc_8">事务的启动方式</h3>

<p>长事务有潜在风险，应当尽量避免。MySQL的事务启动方式有以下几种：</p>

<ol>
<li>显式启动事务语句， begin 或 start transaction。配套的提交语句是commit，回滚语句是rollback。</li>
<li>set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个select语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行commit 或 rollback 语句，或者断开连接。</li>
</ol>

<p>有些客户端连接框架会默认连接成功后先执行一个<code>set autocommit=0</code>的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。</p>

<p>因此，我会建议你总是使用<code>set autocommit=1</code>, 通过显式语句的方式来启动事务。</p>

<p>但是可能会出现“多一次交互”的问题。对于一个需要频繁使用事务的业务，第二种方式每个事务在开始时都不需要主动执行一次 “begin”，减少了语句的交互次数。其实可以使用commit work and chain语法。在autocommit为1的情况下，用begin显式启动的事务，如果执行commit则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行begin语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。</p>

<p>你可以在information_schema库的innodb_trx这个表中查询长事务，比如下面这个语句，用于查找持续时间超过60s的事务。</p>

<pre class="line-numbers"><code class="language-sql">select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(), trx_started)) &gt; 60
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[02 | 日志系统：一条SQL更新语句是如何执行的？]]></title>
    <link href="http://565785929.github.io/16302079765954.html"/>
    <updated>2021-08-29T11:32:56+08:00</updated>
    <id>http://565785929.github.io/16302079765954.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">redo log（重做日志）</a>
</li>
<li>
<a href="#toc_1">binlog（归档日志）</a>
<ul>
<li>
<a href="#toc_2">两阶段提交</a>
</li>
</ul>
</li>
<li>
<a href="#toc_3">redo log 和 binlog 区别</a>
</li>
</ul>


<blockquote>
<p>来自MySQL实战45讲</p>
</blockquote>

<p>与查询流程不一样的是，更新流程还涉及两个重要的日志模块，它们正是我们今天要讨论的主角：</p>

<h2 id="toc_0">redo log（重做日志）</h2>

<p>redo log为InnoDB特有的日志，用来保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。</p>

<p>WAL技术，WAL的全称是Write-Ahead Logging，它的关键点就是先写日志，再写磁盘。具体来说，当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。</p>

<p>InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB，那么总共就可以记录4GB的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。</p>

<p><img src="media/16302079765954/16302100687432.jpg" alt=""/></p>

<p>write pos是当前记录的位置，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。checkpoint是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。</p>

<p>write pos和checkpoint之间的是空着的部分，可以用来记录新的操作。如果write pos追上checkpoint，表示日志满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把checkpoint推进一下。</p>

<h2 id="toc_1">binlog（归档日志）</h2>

<p>binlog是MySQL的Server层实现的，所有引擎都可以使用。</p>

<p>有了对这两个日志的概念性理解，我们再来看执行器和InnoDB引擎在执行这个简单的update语句时的内部流程。</p>

<ol>
<li><p>执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。</p></li>
<li><p>执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。</p></li>
<li><p>引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。</p></li>
<li><p>执行器生成这个操作的binlog，并把binlog写入磁盘。</p></li>
<li><p>执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。</p></li>
</ol>

<p>这里我给出这个update语句的执行流程图，图中浅色框表示是在InnoDB内部执行的，深色框表示是在执行器中执行的。</p>

<p><img src="media/16302079765954/16302234815627.jpg" alt=""/></p>

<p>你可能注意到了，最后三步看上去有点“绕”，将redo log的写入拆成了两个步骤：prepare和commit，这就是&quot;两阶段提交&quot;。</p>

<h3 id="toc_2">两阶段提交</h3>

<p>binlog会记录所有的逻辑操作，并且是采用“追加写”的形式。当数据库需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：</p>

<ul>
<li>首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库；</li>
<li>然后，从备份的时间点开始，将备份的binlog依次取出来，重放到中午误删表之前的那个时刻。</li>
</ul>

<p>由于redo log和binlog是两个独立的逻辑，如果不用两阶段提交，要么就是先写完redo log再写binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。</p>

<p>仍然用前面的update语句来做例子。假设当前ID=2的行，字段c的值是0，再假设执行update语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了crash，会出现什么情况呢？</p>

<ul>
<li><p>先写redo log后写binlog。假设在redo log写完，binlog还没有写完的时候，MySQL进程异常重启。由于我们前面说过的，redo log写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行c的值是1。<br/>
但是由于binlog没写完就crash了，这时候binlog里面就没有记录这个语句。因此，之后备份日志的时候，存起来的binlog里面就没有这条语句。<br/>
然后你会发现，如果需要用这个binlog来恢复临时库的话，由于这个语句的binlog丢失，这个临时库就会少了这一次更新，恢复出来的这一行c的值就是0，与原库的值不同。</p></li>
<li><p>先写binlog后写redo log。如果在binlog写完之后crash，由于redo log还没写，崩溃恢复以后这个事务无效，所以这一行c的值是0。但是binlog里面已经记录了“把c从0改成1”这个日志。所以，在之后用binlog来恢复的时候就多了一个事务出来，恢复出来的这一行c的值就是1，与原库的值不同。</p></li>
</ul>

<p>简单说，redo log和binlog都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。</p>

<p>主从库：需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用binlog来实现的。</p>

<p><img src="media/16302079765954/16306001938527.jpg" alt=""/></p>

<h2 id="toc_3">redo log 和 binlog 区别</h2>

<p>这两种日志有以下三点不同。</p>

<ol>
<li><p>redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。</p></li>
<li><p>redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。</p></li>
<li><p>redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</p></li>
</ol>

<p>redo log用于保证crash-safe能力。innodb_flush_log_at_trx_commit这个参数设置成1的时候，表示每次事务的redo log都直接持久化到磁盘。这个参数我建议你设置成1，这样可以保证MySQL异常重启之后数据不丢失。</p>

<p>sync_binlog这个参数设置成1的时候，表示每次事务的binlog都持久化到磁盘。这个参数我也建议你设置成1，这样可以保证MySQL异常重启之后binlog不丢失。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[01 | 基础架构：一条SQL查询语句是如何执行的？]]></title>
    <link href="http://565785929.github.io/16301414327814.html"/>
    <updated>2021-08-28T17:03:52+08:00</updated>
    <id>http://565785929.github.io/16301414327814.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">Server层</a>
<ul>
<li>
<a href="#toc_1">连接器</a>
</li>
<li>
<a href="#toc_2">查询缓存</a>
</li>
<li>
<a href="#toc_3">分析器</a>
</li>
<li>
<a href="#toc_4">优化器</a>
</li>
<li>
<a href="#toc_5">执行器</a>
</li>
</ul>
</li>
<li>
<a href="#toc_6">存储引擎</a>
</li>
</ul>


<blockquote>
<p>来自MySQL实战45讲</p>
</blockquote>

<p><strong>MySQL的逻辑架构图</strong><br/>
<img src="media/16301414327814/16301415100109.jpg" alt=""/></p>

<p>大体来说，MySQL可以分为Server层和存储引擎层两部分。</p>

<h2 id="toc_0">Server层</h2>

<p>包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。</p>

<h3 id="toc_1">连接器</h3>

<p>第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接命令一般是这么写的：</p>

<pre class="line-numbers"><code class="language-text">mysql -h$ip -P$port -u$user -p
</code></pre>

<p>连接命令中的mysql是客户端工具，用来跟服务端建立连接。在完成经典的TCP握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。</p>

<ul>
<li>如果用户名或密码不对，你就会收到一个&quot;Access denied for user&quot;的错误，然后客户端程序结束执行。</li>
<li>如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。</li>
</ul>

<p>这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。</p>

<p>连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在<code>SHOW PROCESSLIST;</code>命令中看到它。</p>

<p>文本中这个图是show processlist的结果.</p>

<p><img src="media/16301414327814/16301432706534.jpg" alt="" style="width:572px;"/></p>

<p>其中的Command列显示为“Sleep”的这一行，就表示现在系统里面有一个空闲连接。<br/>
其中的Command列显示为“Query”的这一行，就表示当前正在运行<code>SHOW PROCESSLIST;</code>的连接。</p>

<p>客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数wait_timeout控制的，默认值是8小时。可以通过<code>SHOW VARIABLES LIKE &#39;wait_timeout&#39;;</code>或<code>SELECT @@wait_timeout;</code>命令查看。<br/>
<img src="media/16301414327814/16301437610835.jpg" alt="" style="width:307px;"/></p>

<p>如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒： </p>

<blockquote>
<p>Lost connection to MySQL server during query。</p>
</blockquote>

<p>这时候如果你要继续，就需要重连，然后再执行请求了。建立连接的过程通常是比较复杂的，尽量使用长连接。</p>

<p>但是全部使用长连接后，有些时候MySQL占用内存涨得特别快，这是因为MySQL在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是MySQL异常重启了。</p>

<p><strong>怎么解决长连接消耗太多内存呢？你可以考虑以下两种方案。</strong></p>

<ol>
<li><p>定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。</p></li>
<li><p>如果你用的是MySQL 5.7或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。</p></li>
</ol>

<h3 id="toc_2">查询缓存</h3>

<p>连接建立完成后，你就可以执行select语句了。执行逻辑就会来到第二步：查询缓存。</p>

<p>MySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。如果你的查询能够直接在这个缓存中找到key，那么这个value就会被直接返回给客户端。</p>

<p>如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。你可以看到，如果查询命中缓存，MySQL不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。</p>

<p>但是查询缓存往往弊大于利，查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。</p>

<p>好在MySQL也提供了这种“按需使用”的方式。你可以将参数query_cache_type设置成DEMAND，这样对于默认的SQL语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用SQL_CACHE显式指定，像下面这个语句一样：</p>

<pre class="line-numbers"><code class="language-sql">mysql&gt; select SQL_CACHE * from T where ID=10；
</code></pre>

<p>需要注意的是，MySQL 8.0版本直接将查询缓存的整块功能删掉了，也就是说8.0开始彻底没有这个功能了。</p>

<h3 id="toc_3">分析器</h3>

<p>如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL需要知道你要做什么，因此需要对SQL语句做解析。</p>

<p>分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条SQL语句，MySQL需要识别出里面的字符串分别是什么，代表什么。</p>

<p>然后做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个SQL语句是否满足MySQL语法。</p>

<p>如果你的语句不对，就会收到类似如下错误提醒：</p>

<blockquote>
<p>ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &#39;elect * from t where ID=1&#39; at line 1</p>
</blockquote>

<p>一般语法错误会提示第一个出现错误的位置，所以你要关注的是紧接“use near”的内容。</p>

<h3 id="toc_4">优化器</h3>

<p>优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。比如你执行下面这样的语句，这个语句是执行两个表的join：</p>

<blockquote>
<p>mysql&gt; select * from t1 join t2 using(ID)  where t1.c=10 and t2.d=20;</p>
</blockquote>

<ul>
<li>既可以先从表t1里面取出c=10的记录的ID值，再根据ID值关联到表t2，再判断t2里面d的值是否等于20。</li>
<li>也可以先从表t2里面取出d=20的记录的ID值，再根据ID值关联到t1，再判断t1里面c的值是否等于10。</li>
</ul>

<p>这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。优化器阶段完成后，这个语句的执行方案就确定下来了。</p>

<h3 id="toc_5">执行器</h3>

<p>MySQL通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。</p>

<p>开始执行的时候，要先判断一下你对这个表T有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示。</p>

<blockquote>
<p>ERROR 1142 (42000): SELECT command denied to user &#39;b&#39;@&#39;localhost&#39; for table &#39;T&#39;</p>
</blockquote>

<p>如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。</p>

<p>比如我们这个例子中的表T中，ID字段没有索引，那么执行器的执行流程是这样的：</p>

<ol>
<li><p>调用InnoDB引擎接口取这个表的第一行，判断ID值是不是10，如果不是则跳过，如果是则将这行存在结果集中；</p></li>
<li><p>调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。</p></li>
<li><p>执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。</p></li>
</ol>

<p>至此，这个语句就执行完成了。</p>

<p>对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。</p>

<p>你会在数据库的慢查询日志中看到一个rows_examined的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。</p>

<p>在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟rows_examined并不是完全相同的。</p>

<h2 id="toc_6">存储引擎</h2>

<p>而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持</p>

<ul>
<li>InnoDB</li>
<li>MyISAM</li>
<li>Memory</li>
</ul>

<p>等多个存储引擎。可以通过<code>SHOW ENGINES;</code>查看，现在最常用的存储引擎是InnoDB，它从MySQL 5.5.5版本开始成为了默认存储引擎。在create table语句中使用<code>engine=memory</code>, 可以来指定使用内存引擎创建表。</p>

<p><img src="media/16301414327814/16301424628810.jpg" alt="" style="width:860px;"/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[改善代码质量规约]]></title>
    <link href="http://565785929.github.io/16261043857914.html"/>
    <updated>2021-07-12T23:39:45+08:00</updated>
    <id>http://565785929.github.io/16261043857914.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">命名与注释(Naming and Comments)</h2>

<h3 id="toc_1">命名</h3>

<h4 id="toc_2">一、命名长度</h4>

<h4 id="toc_3">二、利用上下文来简化命名</h4>

<pre class="line-numbers"><code class="language-text">public class User {
  private String userName;
  private String userPassword;
  private String userAvatarUrl;
  //...
}
</code></pre>

<p>在User类这样一个上下文中，我们没有在成员变量的命名中重复添加 &quot;user&quot; 这样一个前缀单词，而是直接命名为name, password, avatarUrl。在使用这些属性的时候，我们能借助对象这样一个上下文，表意也足够明确。</p>

<pre class="line-numbers"><code class="language-text">User user = new User();
user.getName(); // 借助user对象这个上下文
</code></pre>

<p>除了类之外，函数参数也可以借助函数这个上下文来简化命名。</p>

<pre class="line-numbers"><code class="language-text">public void uploadUserAvatarImageToAliyun(String userAvatarImageUri);
// 利用上下文简化为：
public void uploadUserAvatarImageToAliyun(String imageUri);
</code></pre>

<h4 id="toc_4">三、命名</h4>

<h3 id="toc_5">注释</h3>

<h4 id="toc_6">一、注释写什么</h4>

<pre class="line-numbers"><code class="language-text">/**
* (what) Bean factory to create beans. 
* 
* (why) The class likes Spring IOC framework, but is more lightweight. 
*
* (how) Create objects from different sources sequentially:
* user specified object &gt; SPI &gt; configuration &gt; default object.
*/
public class BeansFactory {
  // ...
}
</code></pre>

<h4 id="toc_7">二、</h4>

<h2 id="toc_8">代码风格(Code Style)</h2>

<h2 id="toc_9">编程技巧(Coding Tips)</h2>

<ul>
<li></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[为什么需要版本控制]]></title>
    <link href="http://565785929.github.io/16253298632146.html"/>
    <updated>2021-07-04T00:31:03+08:00</updated>
    <id>http://565785929.github.io/16253298632146.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">概述</h2>

<p>在软件开发过程，每天都会产生新的代码，代码合并的过程中可能会出现如下问题：</p>

<ul>
<li>  代码被覆盖或丢失</li>
<li>  代码写的不理想希望还原之前的版本</li>
<li>  希望知道与之前版本的差别</li>
<li>  是谁修改了代码以及为什么修改</li>
<li>  发版时希望分成不同的版本(测试版、发行版等)</li>
</ul>

<p>因此，我们希望有一种机制，能够帮助我们：</p>

<ul>
<li>  可以随时回滚到之前的版本</li>
<li>  协同开发时不会覆盖别人的代码</li>
<li>  留下修改记录，以便随时查看</li>
<li>  发版时可以方便的管理不同的版本</li>
</ul>

<h2 id="toc_1">什么是版本控制系统</h2>

<p>一个标准的版本控制系统 Version Control System (VCS)，通常需要有以下功能：</p>

<ul>
<li>  能够创建 Repository (仓库)，用来保存代码</li>
<li>  协同开发时方便将代码分发给团队成员</li>
<li>  记录每次修改代码的内容、时间、原因等信息</li>
<li>  能够创建 Branch (分支)，可以根据不同的场景进行开发</li>
<li>  能够创建 Tag (标签)，建立项目里程碑</li>
</ul>

<h2 id="toc_2">什么是Svn</h2>

<p><img src="media/16253298632146/16253300167643.jpg" alt=""/></p>

<p>Subversion(SVN) 是一个开源的版本控制系統, 也就是说 Subversion 管理着随时间改变的数据。 这些数据放置在一个中央资料档案库(repository) 中。 这个档案库很像一个普通的文件服务器, 不过它会记住每一次文件的变动。 这样你就可以把档案恢复到旧的版本, 或是浏览文件的变动历史。</p>

<p>日常开发过程其实就是这样的（假设你已经Checkout并且已经工作了几天）：</p>

<ol>
<li>Update(获得最新的代码) --&gt;</li>
<li>作出自己的修改并调试成功 --&gt; </li>
<li>Commit(大家就可以看到你的修改了) </li>
</ol>

<p>如果两个程序员同时修改了同一个文件呢, SVN 可以合并这两个程序员的改动，实际上SVN管理源代码是以行为单位的，就是说两个程序员只要不是修改了同一行程序，SVN都会自动合并两种修改。如果是同一行，SVN 会提示文件 Conflict, 冲突，需要手动确认。</p>

<h2 id="toc_3">什么是Git</h2>

<p><img src="media/16253298632146/16253299182713.jpg" alt=""/></p>

<ul>
<li>Git 是一个开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目。</li>
<li>Git 是 Linus Torvalds 为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件。</li>
<li>Git 与常用的版本控制工具 CVS, Subversion 等不同，它采用了分布式版本库的方式，不必服务器端软件支持。</li>
</ul>

<h2 id="toc_4">版本控制系统的发展史</h2>

<p>版本控制系统发展至今有几种不同的模式：</p>

<h3 id="toc_5">Local VCS</h3>

<p>本地使用 <code>复制/粘贴</code> 的方式进行管理，缺点是无法协同开发</p>

<h3 id="toc_6">Centralized VCS (Lock，悲观锁)</h3>

<p>中央集中式版本控制系统团队共用仓库，当某人需要编辑文件时，进行锁定，以免其他人同时编辑时造成冲突。缺点是虽然避免了冲突，但不是很方便。其他人需要排队才能编辑文件，如果有人编辑了很久或是忘记解锁就会造成其他人长时间等待的情况。</p>

<h3 id="toc_7">Centralized VCS (Merge，乐观锁)</h3>

<p>中央集中式版本控制系统团队共用仓库，不采用悲观锁方式来避免冲突，而是事后发现如果别人也修改相同文件(冲突)，再进行手动修改解决。有很多 VCS 属于这种类型，如：CVS，Subversion，Perforce 等</p>

<p>中央集中式版本控制系统的共同问题是，做任何操作都需要和服务器同步，如果服务器宕机则会造成无法继续工作的窘迫。</p>

<h3 id="toc_8">Distributed VCS</h3>

<p>分布式版本控制系统，本地也拥有完整的代码仓库，就不会出现上述集中式管理的问题，即使没有网络，依然可以 <code>commit</code> 和看 <code>log</code>，也无需担心服务器同步问题。如：Git，Mercurial，Bazaar 等就属于分布式版本控制系统。缺点是功能比较复杂，上手需要一定的学习时间。</p>

<p>本教程来自<a href="https://www.funtl.com/zh/git/">千锋教育-李卫民</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[常见Git仓库]]></title>
    <link href="http://565785929.github.io/16253295942611.html"/>
    <updated>2021-07-04T00:26:34+08:00</updated>
    <id>http://565785929.github.io/16253295942611.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">GitHub</h2>

<h2 id="toc_1">GitLab</h2>

<p><img src="media/16253295942611/16253303567762.jpg" alt=""/></p>

<p><a href="http://bdgit.eigpay.com/">http://bdgit.eigpay.com/</a></p>

<p>git是一个版本管理软件，由linux之父花了三天搞出来的东西，他没有界面，只支持命令行。</p>

<p>github是一个网站，因为git没有图形界面，github它支持在线的几乎所有git的操作，最重要它也是一个包含了很多程序员的开源社区。</p>

<p>gitlib 是用于实现git功能的开发库</p>

<p>gitlab提倡开源，如果你不想开源就要花钱，你如果不愿意花钱，就自己搞个服务器，装gitlab这个软件来实现自己的版本控制，有点私服的概念。</p>

<p>作者：笑笑酱丶<br/>
链接：<a href="https://www.jianshu.com/p/26fa7df41c9a">https://www.jianshu.com/p/26fa7df41c9a</a><br/>
来源：简书<br/>
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ray Tracing for one week]]></title>
    <link href="http://565785929.github.io/16197951416649.html"/>
    <updated>2021-04-30T23:05:41+08:00</updated>
    <id>http://565785929.github.io/16197951416649.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[科学上网]]></title>
    <link href="http://565785929.github.io/16137917098988.html"/>
    <updated>2021-02-20T11:28:29+08:00</updated>
    <id>http://565785929.github.io/16137917098988.html</id>
    <content type="html"><![CDATA[
<p><img src="media/16137917098988/16193973348755.jpg" alt="" style="width:150px;"/></p>

<h2 id="toc_0">背景</h2>

<p>自从天朝有了言论管制，科学上网的话题就一直存在，于是大量的梯子软件应运而生。但是GFW与这些梯子软件的斗争从来都没有停止过，一直是此消彼长，墙越来越高，科学上网技术也是持续突破，不断涌现出新技术、新工具。现在最主流的科学上网技术有VPN/SS/SSR/V2Ray/Trojan/Trojan-Go，还有小众的 WireGuard、Brook、Snell 和 NaiveProxy 等，本篇文章不讨论Brook、NaiveProxy以及Snell协议。SS是科学上网代理协议的鼻祖，Snell和Brook是小众协议，Snell协议一直没有开源，是iOS平台非常知名的Surge软件团队开发的专属协议，Brook配套设施不完善；其中，VPN/SS/SSR最为出名，V2Ray和Trojan/Trojan-Go作为新星，正在受到越来越多的关注和使用。</p>

<h2 id="toc_1">什么是VPN和WireGuard，它们有什么关系？</h2>

<p>VPN是英文 Virtual Private Network 的缩写，中文名称为虚拟专用网络，是一种加密通信技术。VPN 只是一个统称，它有很多的具体实现，比如PPTP、L2TP、IPSec和OpenVPN等。VPN是在公用网络上建立专用网络，并对通信进行加密，防止传输数据被识别或篡改，以保障通信的安全。当你在VPN网络中通信，就相当于通过物理的内网专线进行通信。由此可见，VPN绝不是为了科学上网而生，而是更加注重数据信息的安全，很多大型企业和高校的远程SOHO办公使用VPN较多。</p>

<p>WireGuard 是最新开发的VPN协议，比主流的VPN技术有明显优势，被誉为下一代VPN。WireGuard有如下特点：</p>

<p>WireGuard 的优点：</p>

<ul>
<li>更轻便：以Linux内核模块的形式运行，资源占用小。</li>
<li>更高效：相比目前主流的IPSec、OpenVPN等VPN协议，WireGuard的效率要更高。</li>
<li>更快速：比目前主流的VPN协议，连接速度要更快。</li>
<li>更安全：使用了更先进的加密技术。</li>
<li>更易搭建：部署难度相对更低。</li>
<li>更隐蔽：以UDP协议进行数据传输，比TCP协议更低调。</li>
<li>不易被封锁：TCP阻断对WireGuard无效，IP被墙的情况下仍然可用。</li>
<li>更省电：不使用时不进行数据传输，移动端更省电。</li>
</ul>

<p>WireGuard 的不足：</p>

<ul>
<li>处于研发初期，各种功能及支持有待完善。</li>
<li>由于使用UDP协议，BBR、锐速等TCP网络加速工具，对WireGuard无效。</li>
<li>部分运营商可能会对UDP协议进行QOS限速，WireGuard会受到一定影响。</li>
<li>客户端分流功能较弱，对GFWList的支持不足。</li>
</ul>

<p>WireGuard虽然有一些不足，但WireGuard的优点更突出，而且可以拯救被封IP的VPS，所以 WireGuard 是 SS/SSR/V2Ray/Trojan 等代理工具之外的一个不错的选择。</p>

<h2 id="toc_2">什么是 Shadowsocks？</h2>

<p>SS 是 Shadowsocks 的缩写，中文名为影梭，为了避免关键词过滤，网友喜欢将 Shadowsocks 称为“酸酸”，是一种基于Socks5代理方式的加密传输协议，也可以指实现这个协议的各种开发包。Shadowsocks 由 Clowwindy 为了自己使用谷歌查资料而编写，Shadowsocks分为服务器端和客户端，在使用之前，需要先将服务器端程序部署到服务器上面，然后通过客户端连接并创建本地代理。后来，他觉得这个东西非常好用、速度也很快，于是他在 GitHub 上共享了源码。在天朝，本工具被广泛用于突破GFW，以浏览被封锁、遮蔽或干扰的内容，由于 Shadowsocks 被广泛传播，导致作者被请去喝茶。2015年8月22日，Shadowsocks 原作者 Clowwindy 称迫于天朝内部的压力，宣布停止维护此计划（项目），并移除其个人页面所存储的源代码，而且保证永不再参与维护更新。值得庆幸地是，Shadowsocks 仍然有不少国外社区成员在维护更新。后来贡献者Librehat也为Shadowsocks补上了一些数据混淆类特性，甚至增加了类似Tor的可插拔传输层功能。</p>

<h2 id="toc_3">什么是 ShadowsocksR</h2>

<p>SSR 是 ShadowsocksR 的缩写，网民爱称“酸酸乳”，是在 Shadowsocks 的作者被请去喝茶之后，网名为breakwa11的用户发起的Shadowsocks的一个分支版本，它在Shadowsocks的基础上增加了一些数据混淆方式，修复了部分安全问题并提高QoS优先级。由于 ShadowsocksR 在协议和混淆方面做了改进，更加不容易被GFW检测到，而且兼容原 Shadowsocks，并为新项目取名叫 Shadowsocks-R，一开始部分代码由社区人员进行更新。由于不完全开源，也导致后来使用 SS 和 SSR 的用户分成两个阵营，互相撕逼，直到开发者 Breakwa11(破娃) 被人肉出来。Breakwa11(破娃)最终决定删除 Shadowsocks-R 项目的所有代码，并解散了所有相关群组。</p>

<p>事件始末澄清：ShadowsocksR 的作者一开始曾有过违反GPL，在发布二进制文件时不开放源码的争议。不过后来 Shadowsocks-R 项目由 breakwa11 采用了与 Shadowsocks 相同的GPL、Apache许可证、MIT许可证等多重自由软件许可协议。</p>

<p>2017年7月19日，ShadowsocksR 作者 breakwa11 在Telegram频道 ShadowsocksR news 里转发了深圳市启用SS协议检测的消息并被大量用户转发，在TG圈引发恐慌。7月24日，breakwa11 发布了闭源的SS被动检测程序，引发争议。7月27日，breakwa11 遭到自称 “ESU.TV” 的不明身份人士人身攻击，对方宣称如果不停止开发并阻止用户讨论此事件将发布更多包含个人隐私的资料，随后 breakwa11 表示遭到对方人肉搜索并公开个人资料的是无关人士。为了防止对方继续伤害无关人士，breakwa11 将删除GitHub上的所有代码、解散相关交流群组，并停止 ShadowsocksR 项目。</p>

<p>从本质上说，Shadowsocks 和 ShadowsocksR 的基本原理相同，都是基于 socks5 的代理工具，只在本地客户端和服务器端对数据包加解密，然后使用 socks5 协议转发加密的数据包，而不用在乎使用什么协议，所以 Socks5 代理比其他应用层代理速度要快得多。</p>

<h2 id="toc_4">【科普】什么是 socks5 代理？</h2>

<p>socks5 代理的原理是把你的网络数据请求先发送到你的代理服务器，然后由代理服务器转发给目标；如果目标有反馈发送到代理服务器，那么代理服务器会将数据包直接传回你的本地网络，整个过程只是数据的二次传输，并没有做额外的处理。比如，现在你在深圳，你的代理服务器在日本，如果你想要访问Google，那么你首先要把数据请求通过本地 socks5 代理客户端发给你在香港的服务器上的 socks5 代理服务端，然后你在香港的服务器将数据请求发送给Google，再把Google反馈的结果传回你的本地电脑的 socks5 客户端，这样就可以绕开GFW的检测而实现科学上网。</p>

<p>显而易见，socks5代理的所有数据走的仍然是公网，而且在公网传输过程中，没有对数据进行任何加密和混淆，这跟VPN在公网建立虚拟专用通道传输过程中，对数据高强度加密的方式完全不同。Shadowsocks 和 ShadowsocksR 只在客户端和服务器端对数据做了简单加密和认证，主要功能是流量转发，过墙才是主要目的。虽然现在 ShadowsocksR 已经停止更新很久了，而 Shadowsocks 仍处于社区人员的更新维护之中，不断修复漏洞并增加新功能，所以现在 Shadowsocks 比 ShadowsocksR 更强大。</p>

<p><strong>我在此提醒大家</strong>：请不要迷信 SSR 一定比 SS 强，也包括现在的V2Ray、Trojan，甚至WireGuard等，因为增加混淆意味着损失速度，混淆加密越是强悍，那么其速度和稳定性损失就越大，另外 SSR 至今已经被研究透了，而且长期没有更新维护，其流量特征是可以被GFW精准识别的，所以用 SSR 跟用 SS 没有本质区别，由于SS一直在更新维护，反而更稳定。我们要做的就是爱国爱家爱生活，勿谈国是，专心做好自己的事情就是了。天朝一直都清楚，跨境相关业务一直存在，尤其是近些年跨境电商的蓬勃发展，很多做跨境相关业务的朋友不外出通讯是不可能的一件事情，但所谓的公司备案VPN却非常昂贵，一般用户根本承担不起费用。但我们一定要“做好分内事，勿论他人非”，尤其不发表涉及天朝的言论和行为，做一个天朝的好公民、中华的好儿女，这样天朝是没有必要跟她的好儿女过不去的。</p>

<h2 id="toc_5">什么是 V2Ray？</h2>

<p>V2Ray 是在Shadowsocks 被封杀之后，为了表示抗议而开发的，属于后起之秀，功能更加强大，为抗GFW封锁而生。V2Ray 现在已经是 Project V 项目的核心工具，而 Project V 是一个平台，其中也包括支持 Shadowsocks 协议。由于 V2Ray 早于 Project V 项目，而且名声更大，所以我们习惯称 Project V 项目为 V2Ray，所以我们平时所说的 V2Ray 其实就是 Project V  这个平台，也就是一个工具集。其中，只有 VMess协议是V2Ray社区原创的专属加密通讯协议，被广泛应用于梯子软件。</p>

<p>V2Ray目前支持以下协议（截止到2019年12月）：</p>

<ul>
<li>Blackhole：中文名称“黑洞”，是一个出站数据协议，它会阻碍所有数据的出站，配合路由（Routing）一起使用，可以达到禁止访问某些网站的效果。</li>
<li>Dokodemo-door：中文名称“任意门”，是一个入站数据协议，它可以监听一个本地端口，并把所有进入此端口的数据发送至指定服务器的一个端口，从而达到端口映射的效果。</li>
<li>Freedom：是一个出站协议，可以用来向任意网络发送（正常的） TCP 或 UDP 数据。</li>
<li>HTTP：超文本传输协议，是传统的代理协议</li>
<li>MTProto：Telegram 的开发团队开发的专用协议，是一个 Telegram 专用的代理协议。在 V2Ray 中可使用一组入站出站代理来完成 Telegram 数据的代理任务。目前只支持转发到 Telegram 的 IPv4 地址。</li>
<li>Shadowsocks：最早被个人开发的科学上网梯子协议，但 V2Ray 目前不支持 ShadowsocksR。</li>
<li>Socks：标准 Socks 协议实现，兼容 Socks 4、Socks 4a 和 Socks 5，也是传统的代理协议。</li>
<li>VMess：是V2Ray 专用的加密传输协议，它分为入站和出站两部分，通常作为 V2Ray 客户端和服务器之间的桥梁。因为增加了混淆和加密，据说比 Shadowsocks 更安全。现在的机场支持 V2Ray，一般是指支持 VMess 协议。VMess 依赖于系统时间，请确保使用 V2Ray 的系统 UTC 时间误差在 90 秒之内，时区无关。在 Linux 系统中可以安装ntp服务来自动同步系统时间。</li>
</ul>

<p>截止到2019年12月，V2Ray 可选的传输层配置有：TCP、mKCP、WebSocket、HTTP/2、DomainSocket、QUIC。其中，mKCP、QUIC和TCP用于优化网络质量；WebSocket用于伪装；HTTP/2和DomainSocket用于传输以及TLS加密。</p>

<p>V2Ray不仅可以在传输层配置 TLS 使 HTTP 和 SOCKS 变成 HTTPS 和 SOCKS over TLS 协议，也可以使MTProto、Shadowsocks 和 VMess 通过传输层配置TLS加密伪装成 TLS 流量。所以，VMess 配置 TLS 加密是最常见的做法，但没人会对 Shadowsocks 使用 TLS 加密，因为这完全没意义。</p>

<h2 id="toc_6">什么是 Trojan/Trojan-Go？</h2>

<p>Trojan，原来多是指特洛伊木马，是一种计算机病毒程序。但是，我们今天所说的Trojan是一种新的科学上网技术，全称为Trojan-GFW，是目前最成功的科学上网伪装技术之一。你可以认为Trojan是V2Ray的“WS+TLS”模式的精简版，速度比V2Ray更快，伪装比V2Ray更逼真，更难以被GFW识别。</p>

<p>Trojan工作原理：Trojan通过监听443端口，模仿互联网上最常见的 HTTPS 协议，把合法的Trojan代理数据伪装成正常的 HTTPS 通信，并真正地完整完成的TLS 握手，以诱骗GFW认为它就是 HTTPS，从而不被识别。Trojan处理来自外界的 HTTPS 请求，如果是合法的，那么为该请求提供服务，否则将该流量转交给Caddy、Nginx等 web 服务器，由 Caddy、Nginx 等为其提供网页访问服务。基于整个交互过程，这样能让你的VPS更像一个正常的web服务器，因为Trojan的所有行为均与 Caddy、Nginx等 web 服务器一致，并没有引入额外特征，从而达到难以识别的效果。</p>

<p>Trojan-Go是Trojan-GFW的分支项目，对Trojan进行性能优化，并增加不少新功能，Trojan-Go性能和功能均有大幅度的提升，而且支持分流和CDN。</p>

<h2 id="toc_7">什么是Xray？</h2>

<p>Xray与V2Ray完全类同，Xray 是 Project X 项目的核心模块。因为Xray和XTLS黑科技的作者rprx曾经是V2fly社区的重要成员，所以Xray直接Fork全部V2Ray的功能，然后进行性能优化，并增加了新功能，使Xray在功能上成为了V2Ray的超集，且完全兼容V2Ray。</p>

<p>简而言之，Xray是V2Ray的项目分支，Xray是V2Ray的超集，就跟Trojan-Go和Trojan-GFW的关系类似，而且Xray性能更好、速度更快，更新迭代也更频繁。由于自V2ray-core 4.33.0 版本起，删除了XTLS黑科技，但仍然支持VLESS，所以是否原生支持XTLS是Xray和V2Ray最大的区别之一。</p>

<h2 id="toc_8">VPN、SS/SSR、V2Ray/Xray 和 Trojan/Trojan-Go 之间有什么区别及优缺点</h2>

<h3 id="toc_9">（1）原理不同</h3>

<p>VPN强调对公网传输过程中数据的加解密，SS/SSR/V2Ray/Xray/Trojan都是专注于在客户端和服务器端加解密，公网传输数据过程中特征没有VPN明显。</p>

<h3 id="toc_10">（2）目的不同</h3>

<p>VPN是走在公网中自建的虚拟专用通道，使用强大的加解密算法，为数据传输安全性、私密性而生，被广泛应用于企业、高校、科研部门等远程数据传输的领域；SS/SSR/V2Ray/Xray/Trojan/Trojan-Go是为了数据能够安全通过GFW而生，更强调的是对数据的混淆和伪装，加解密只是为了更好的隐藏数据特征而顺利绕过GFW的检测，数据内容加密可以有效绕过关键词的检测。</p>

<p>在天朝，如果你想用VPN翻墙几乎是不可能的，在平时不怎么限制还好，特殊时期VPN是断流最惨的。如果要需要匿名安全上网，VPN+TOR或SS/SSR+TOR也是不错的选择。当然，现在已经有了新的对抗技术，比如V2Ray/Xray、Trojan/Trojan-Go、WireGuard等。另外，有一些比较著名的工具，如红杏出墙、蓝灯（Lantern）、Tor Browser、赛风3（Psiphon3）等，都相继被墙，现在已经很少人使用了。</p>

<h2 id="toc_11">项目诞生的大致时间顺序</h2>

<p>VPN &gt; SS &gt; SSR/V2Ray/WireGuard &gt; Trojan/Trojan-Go &gt; Xray</p>

<h2 id="toc_12">对梯子软件/科学上网工具的总结</h2>

<p>VPN虽然天生不是为了做梯子，但却是最出名的梯子软件、众人皆知的科学上网工具，但是由于VPN特征太明显，现在非大陆正规公司的VPN基本被禁的差不多了；SS/SSR为科学上网而生，但是加密和混淆较弱，而且已经被GFW精准识别，在科学上网方面的前景堪忧，但是仍然适用于专线，网络速度比V2Ray/Trojan/Trojan-Go更快；V2Ray/Xray为科学上网而生，天生不凡，已经成长为一个平台框架，拥有自研协议VMess和VLESS，功能非常强大；WireGuard被誉为新一代VPN，技术强大，而且已经被写入Linux内核，前景光明，但是在科学上网方面并不够隐蔽，所以不是未来主流的科学上网工具；Trojan/Trojan-Go为科学上网而生，天生只为了模仿互联网最流行的HTTPS协议而存在，是目前最成功的伪装工具之一，功能与V2Ray的“Vmess+WS+TLS”模式相当，但是更轻量，伪装更逼真，目前GFW几乎无法识别其特征，而且目前Trojan-Go在性能和速度方面的表现均优于V2Ray的VMess和VLESS协议。所以，我认为Trojan/Trojan-Go会跟V2Ray一样成为将来科学上网的主流工具之一，SSR由于长期得不到维护而逐渐退出历史舞台，Shadowsocks/SS依然是最轻量的科学上网代理协议，没有之一。</p>

<p><a href="https://iyideng.me/black-technology/cgfw/vpn-ss-ssr-v2ray-trojan-wireguard-bypass-gfw.html">来源</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[自动登录工具开发]]></title>
    <link href="http://565785929.github.io/16110385786886.html"/>
    <updated>2021-01-19T14:42:58+08:00</updated>
    <id>http://565785929.github.io/16110385786886.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">涉及工具技术</h2>

<ul>
<li>Tampermonkey</li>
<li>jQuery</li>
<li>Tesseract-OCR</li>
<li>Flask</li>
<li><a href="https://pillow.readthedocs.io/en/stable/">Pillow</a></li>
</ul>

<h2 id="toc_1">前言</h2>

<p>开发软件系统时必然会有用户登陆的模块。每次验证自己的功能时，总是绕不开输入账号密码，这已经是很麻烦的了，还得输入不好辨认的验证码。</p>

<p>为了简化登陆步骤，我通过使用图像识别 OCR 技术，和Web应用框架Flask搭建一个验证码自动识别的服务。并结合强大的浏览器插件Tampermonkey，编写一个简单的油猴脚本，在不入侵源系统的基础上，实现不输入验证码登陆。也为后期自动化测试奠定可操作的基础。</p>

<h2 id="toc_2">依赖安装</h2>

<p>示例环境Centos8</p>

<pre class="line-numbers"><code class="language-bash">sudo yum install epel-release
sudo yum install tesseract-devel leptonica-devel
 
yum install -y libjpeg-devel  libpng-devel
yum install -y autoconf automake libtool

yum install -y git wget
yum install -y gcc gcc-c++
yum install -y tesseract  tesseract-devel  
yum install -y python36
</code></pre>

<p>创建python虚拟环境</p>

<pre class="line-numbers"><code class="language-bash">python3.6 -m venv py36env
source py36env/bin/activate
</code></pre>

<p>python依赖安装</p>

<pre class="line-numbers"><code class="language-bash">pip install flask
pip install flask_cors
pip install tesserocr
pip install pillow
pip install uwsgi
</code></pre>

<h2 id="toc_3">安装常见错误</h2>

<p><strong>找不到tesseract包</strong></p>

<blockquote>
<p>yum list tesseract <br/>
无数据 </p>
</blockquote>

<p><strong>解决</strong></p>

<pre class="line-numbers"><code class="language-text">yum -y install yum-utils
yum-config-manager --add-repo https://download.opensuse.org/repositories/home:/Alexander_Pozdnyakov/CentOS_8/
</code></pre>

<p><strong>TESSDATA_PREFIX问题</strong></p>

<blockquote>
<p>[Sajor@10-7-151-243 AutoLogin]$ tesseract captcha_denoising.png result <br/>
Error opening data file /usr/share/tesseract/4/tessdata/eng.traineddata<br/>
Please make sure the TESSDATA_PREFIX environment variable is set to your &quot;tessdata&quot; directory.<br/>
Failed loading language &#39;eng&#39;<br/>
Tesseract couldn&#39;t load any languages!<br/>
Could not initialize tesseract.</p>
</blockquote>

<p><strong>解决</strong></p>

<p>搜索tessdata文件夹 </p>

<pre class="line-numbers"><code class="language-text">find / -type d -iname &quot;tessdata&quot;
</code></pre>

<p>发现确实没有 <code>eng.traineddata</code> 文件，则下载一个。</p>

<pre class="line-numbers"><code class="language-text">wget https://github.com/tesseract-ocr/tessdata/raw/master/eng.traineddata

sudo mv -v eng.traineddata /usr/local/share/tessdata/
</code></pre>

<h2 id="toc_4">验证码识别</h2>

<p>我们开发的系统登陆页面是这样的</p>

<p><img src="media/16110385786886/16110394454445.jpg" alt="" style="width:814px;"/></p>

<p>其中验证码图片<br/>
<img src="media/16110385786886/captcha3.png" alt="captcha3"/></p>

<p>先分析此验证码图片有以下特点</p>

<ul>
<li>颜色多样</li>
<li>字母较大，干扰线细</li>
<li>线条笔直无扭曲</li>
</ul>

<p>我们可以这样处理</p>

<h3 id="toc_5">颜色多样</h3>

<p>针对颜色多样，我们可以先给图片做灰度处理再做二值化处理，这是识别前处理验证码的基操。</p>

<blockquote>
<p><strong>灰度图像</strong>: 每个像素用8个bit表示，0表示黑，255表示白，其他数字表示不同的灰度。<br/>
<strong>转换公式</strong>: <code>L = R * 299/1000 + G * 587/1000+ B * 114/1000</code></p>
</blockquote>

<pre class="line-numbers"><code class="language-text">from PIL import Image
image = Image.open(file).convert(&#39;L&#39;)
</code></pre>

<p><img src="media/16110385786886/16110398931116.jpg" alt="" style="width:323px;"/></p>

<p>之后对灰度图片做二值化，使图片非黑即白，可以通过调整下图中<code>threshold</code>的值来过滤少部分颜色浅的干扰线，因为图片中字母部分也可能出现亮黄色的情况，为了防止误删要识别的文字，我将阈值先调高一些，少过滤一些颜色。</p>

<blockquote>
<p><strong>二值图像</strong>: 非黑即白。每个像素用8个bit表示，0表示黑，255表示白。</p>

<pre class="line-numbers"><code class="language-text">image.convert(&#39;1&#39;)
</code></pre>
</blockquote>

<p><img src="media/16110385786886/16110403706745.jpg" alt="" style="width:523px;"/></p>

<h3 id="toc_6">字母较大，干扰线细</h3>

<p>因为字母较大，像素较多，而干扰线的较细，我们可以使用这个策略来去除干扰线。</p>

<pre class="line-numbers"><code class="language-text">遍历图片中每一个像素点：
    如果这个像素点为黑色：
        观察它四面八方的像素点颜色，如果少于四个点为黑色：
            将这个点变为白色
</code></pre>

<p>这个策略的大致意思就是将图像中置于边缘的像素删除掉。因为字母较大，像素比较多，删除一圈也不会有什么影响。</p>

<p><img src="media/16110385786886/16110409153447.jpg" alt="" style="width:310px;"/></p>

<h3 id="toc_7">线条笔直无扭曲</h3>

<p>通过上一步的降噪处理得到的结果已经很好了，因为线条笔直没有扭曲，可以直接丢给OCR来识别了！</p>

<p>网络中现成的OCR识别工具有很多，比如百度OCR，Tesseract-OCR。</p>

<p>第三方的OCR得经过注册，使用他们提供的token调用接口，我就直接使用Python的第三方库Tesseract来搞。</p>

<p>安装必要的包之后直接调用即可。</p>

<pre class="line-numbers"><code class="language-text">import tesserocr
result = tesserocr.image_to_text(image)
</code></pre>

<p><img src="media/16110385786886/16110413762073.jpg" alt="" style="width:360px;"/></p>

<h2 id="toc_8">编写Web接口</h2>

<p>使用Jupyter notebook 验证好功能后，将代码封装成类，方便调用。</p>

<p>之后使用Flask的 helloworld 工程简单修改一下，实现一个可调用的接口。</p>

<p>简单实用<code>uwsgi</code>部署一下这个web项目，配置<code>uwsgi.ini</code>文件将下文中<code>/root/AutoLogin</code>路径改为自己的目录。</p>

<pre class="line-numbers"><code class="language-text">[uwsgi]
master = true
http=:5000
chdir = /root/AutoLogin
wsgi-file=/root/AutoLogin/app.py
callable=app
processes=4
threads=2
buffer-size = 65536
vacuum=true
pidfile =/root/AutoLogin/uwsgi.pid
</code></pre>

<p>启动命令：<br/>
<code>uwsgi --ini uwsgi.ini</code><br/>
重启命令：<br/>
<code>uwsgi --reload uwsgi.pid</code><br/>
关闭命令：<br/>
<code>uwsgi --stop uwsgi.pid</code></p>

<h2 id="toc_9">NginX代理</h2>

<p>新建一个配置文件</p>

<pre class="line-numbers"><code class="language-text">vi /etc/nginx/conf.d/autologin.conf
</code></pre>

<p>输入以下内容</p>

<pre class="line-numbers"><code class="language-text">        server{

                listen       80;
                listen       [::]:80;
                server_name  autoLogin.sajor.top;
                access_log  /var/log/nginx/access.log;
                error_log   /var/log/nginx/error.log;

                location /{
                        proxy_pass http://localhost:5000;
                }
        }
</code></pre>

<p>检查并重启</p>

<pre class="line-numbers"><code class="language-text">nginx -t
service nginx restart
</code></pre>

<p>查看 mem top 10</p>

<pre class="line-numbers"><code class="language-text">ps aux | grep -v PID | sort -rn -k 4| head
</code></pre>

<h2 id="toc_10">--</h2>

<p>-- 未完待续。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[mysql5.7 无法设置0000-00-00默认日期]]></title>
    <link href="http://565785929.github.io/16022150270617.html"/>
    <updated>2020-10-09T11:43:47+08:00</updated>
    <id>http://565785929.github.io/16022150270617.html</id>
    <content type="html"><![CDATA[
<p>问题：<br/>
<img src="media/16022150270617/16125316270697.jpg" alt=""/></p>

<p><img src="media/16022150270617/16125316380058.jpg" alt=""/></p>

<p>使用命令行。navicat不好使</p>

<h2 id="toc_0">解决方案：</h2>

<p>使用root登陆数据库</p>

<ol>
<li>查看sql_mode：
<code>select @@sql_mode;</code></li>
</ol>

<p>获得结果：<br/>
<code>ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION</code></p>

<ol>
<li>NO_ZERO_IN_DATE,NO_ZERO_DATE是无法默认为‘0000-00-00 00:00:00’的根源，去掉之后再次新建表就可以了</li>
</ol>

<p><code>SET GLOBAL sql_mode=&#39;ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION&#39;;</code></p>

<h2 id="toc_1">注：</h2>

<p>NO_ZERO_IN_DATE：在严格模式下，不允许日期和月份为零<br/>
NO_ZERO_DATE：设置该值，mysql数据库不允许插入零日期，插入零日期会抛出错误而不是警告。</p>

<p>测试新建表，ok。可以了。</p>

<h2 id="toc_2">终极解决方案</h2>

<p>修改my.ini配置文件直接修改启动sql_mode<br/>
在[mysqld]下添加<br/>
可以设置<code>sql_mode=ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION</code></p>

<p>或者为了避免group by限制 直接设置为<code>STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION</code></p>

<pre class="line-numbers"><code class="language-text">[mysqld]
sql_mode=STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION
</code></pre>

<p>dos命令重启mysql</p>

<pre class="line-numbers"><code class="language-dos">net stop mysql
net start mysql
</code></pre>

<p><img src="media/16022150270617/16125316826946.jpg" alt=""/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[yum安装提示错误Thread/process failed: Thread died in Berkeley DB librar]]></title>
    <link href="http://565785929.github.io/15914577057463.html"/>
    <updated>2020-06-06T23:35:05+08:00</updated>
    <id>http://565785929.github.io/15914577057463.html</id>
    <content type="html"><![CDATA[
<p>问题描述：#<br/>
yum 安装更新提示 rpmdb: Thread/process failed: Thread died in Berkeley DB library</p>

<p>问题解决：#<br/>
01、删除yum临时库文件</p>

<p><code>rm -fr /var/lib/rpm/__db.*</code></p>

<p>02、重建rpm数据库</p>

<p><code>rpm --rebuilddb</code></p>

<p>03、清理缓存及生产yumdb缓存</p>

<p><code>yum clean all</code><br/>
<code>yum makecache</code></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[离线支付方案]]></title>
    <link href="http://565785929.github.io/15873033963371.html"/>
    <updated>2020-04-19T21:36:36+08:00</updated>
    <id>http://565785929.github.io/15873033963371.html</id>
    <content type="html"><![CDATA[
<h1 id="toc_0">二维码登陆+2FA双因素认证</h1>

<p>二者都是很常用的技术，但是两者相结合遍可以用于二维码离线支付。</p>

<h2 id="toc_1">密码安全</h2>

<p>首先讨论一下如何让密码安全？<br/>
注册时密码数据流，密码首先在web或客户端由用户手动输入，然后经过网络传输至服务端，服务端入库。<br/>
登陆时密码数据流，密码也是在web或客户端由用户手动输入，然后经过网络传输至服务端，服务端查库。</p>

<p>所以我们可以在客户端、网络传输、数据库中分别采用下图方案保护我们的密码。</p>

<p><img src="media/15868546287595/15868573710308.jpg" alt="" style="width:1403px;"/></p>

<h2 id="toc_2">二维码登陆原理</h2>

<p>登录做两件事<br/>
1、告诉系统我是谁;<br/>
2、向系统证明我是谁;</p>

<p>二维码其实是字符串的图片表现形式</p>

<p><strong>基于token的认证机制</strong><br/>
1、首次登录客户端向服务器传送密码+设备信息进行认证;<br/>
2、服务端认证通过后,生成token与设备信息进行对应,并存储在服务端并将token回传到客户端;<br/>
3、客户端每次访问API时,需要携带token+设备信息作为验证信息;<br/>
4、服务端验证token+设备信息是否对应,验证通过后,返回API响应,验证不通过,拒绝服务;<br/>
特别注意:token是某个客户端私有的,即使有token,没有对应的设备信息,也是验证不通过的</p>

<h2 id="toc_3">双因素认证（2FA）</h2>

<p>一般情况下，网站登录都使用账号密码的方式登录，这是最常见的认证方法，但是不安全，容易泄露和冒充。</p>

<h3 id="toc_4">双因素认证概念：</h3>

<p>一般来说，三种不同类型的证据，可以证明一个人的身份。</p>

<ul>
<li>秘密信息：只有该用户知道、其他人不知道的某种信息，比如密码</li>
<li>个人物品：该用户的私人物品，比如身份证、钥匙、手机号</li>
<li>生物特征：该用户的遗传特征，比如指纹、相貌、虹膜等</li>
</ul>

<p>这些证据就称为三种”因素“。因素越多，证明力就越强，身份就越可靠。</p>

<p>双因素认证就是指，通过认证同事需要两个因素的证据。</p>

<p>银行卡取钱就是最常见的双因素认证。用户必须同时提供银行卡和密码，才能取到现金。</p>

<h3 id="toc_5">双因素认证方案</h3>

<p>常用的双因素组合是密码 + 某种个人物品，比如网上银行的 U 盾。用户插上 U 盾，再输入密码，才能登录网上银行。</p>

<p>但是，用户不可能随时携带 U 盾，手机才是最好的替代品。密码 + 手机就成了最佳的双因素认证方案。</p>

<p>国内的很多网站要求，用户输入密码时，还要提供短消息发送的验证码，以证明用户确实拥有该手机。</p>

<p>但是，短消息是不安全的，容易被拦截和伪造，SIM 卡也可以克隆。已经有案例，先伪造身份证，再申请一模一样的手机号码，把钱转走。</p>

<p>因此，安全的双因素认证不是密码 + 短消息，而是下面要介绍的 TOTP。</p>

<h3 id="toc_6">TOTP的概念</h3>

<p>TOTP 的全称是&quot;基于时间的一次性密码&quot;（Time-based One-time Password）。它是公认的可靠解决方案，已经写入国际标准 <a href="https://tools.ietf.org/html/rfc6238">RFC6238</a>。</p>

<p>它的步骤如下。</p>

<p>第一步，用户开启双因素认证后，服务器生成一个密钥。</p>

<p>第二步：服务器提示用户扫描二维码（或者使用其他方式），把密钥保存到用户的手机。也就是说，服务器和用户的手机，现在都有了同一把密钥。<br/>
<img src="media/15847222662823/15847227437312.jpg" alt=""/><br/>
注意，密钥必须跟手机绑定。一旦用户更换手机，就必须生成全新的密钥。</p>

<p>第三步，用户登录时，手机客户端使用这个密钥和当前时间戳，生成一个哈希，有效期默认为30秒。用户在有效期内，把这个哈希提交给服务器。<br/>
<img src="media/15847222662823/15847227654261.jpg" alt=""/><br/>
第四步，服务器也使用密钥和当前时间戳，生成一个哈希，跟用户提交的哈希比对。只要两者不一致，就拒绝登录。</p>

<h3 id="toc_7">TOTP算法</h3>

<p>仔细看上面的步骤，你可能会有一个问题：手机客户端和服务器，如何保证30秒期间都得到同一个哈希呢？</p>

<p>答案就是下面的公式。</p>

<p>TC = floor((unixtime(now) − unixtime(T0)) / TS)</p>

<p>上面的公式中，TC 表示一个时间计数器，unixtime(now)是当前 Unix 时间戳，unixtime(T0)是约定的起始时间点的时间戳，默认是0，也就是1970年1月1日。TS 则是哈希有效期的时间长度，默认是30秒。因此，上面的公式就变成下面的形式。</p>

<p>TC = floor(unixtime(now) / 30)<br/>
所以，只要在 30 秒以内，TC 的值都是一样的。前提是服务器和手机的时间必须同步。</p>

<p>接下来，就可以算出哈希了。</p>

<p>TOTP = HASH(SecretKey, TC)<br/>
上面代码中，HASH就是约定的哈希函数，默认是 SHA-1。</p>

<p>TOTP 有硬件生成器和软件生成器之分，都是采用上面的算法。</p>

<h3 id="toc_8">总结</h3>

<p>双因素认证的优点在于，比单纯的密码登录安全得多。就算密码泄露，只要手机还在，账户就是安全的。各种密码破解方法，都对双因素认证无效。</p>

<p>缺点在于，登录多了一步，费时且麻烦，用户会感到不耐烦。而且，它也不意味着账户的绝对安全，入侵者依然可以通过盗取 cookie 或 token，劫持整个对话（session）。</p>

<p>双因素认证还有一个最大的问题，那就是帐户的恢复。</p>

<p>一旦忘记密码或者遗失手机，想要恢复登录，势必就要绕过双因素认证，这就形成了一个安全漏洞。除非准备两套双因素认证，一套用来登录，另一套用来恢复账户。</p>

<h2 id="toc_9">二维码在线支付</h2>

<p>首先谈一下在线支付方案。<br/>
首先这个二维码其实只是用户的唯一标识。让商户端扫描之后，知道是谁要付款。</p>

<p>所以简单实现，一般为客户端请求服务端，服务端在redis中存储客户信息，一分钟失效。<br/>
然后商户端扫描redis中存储的这个uuid，通过这个uuid获取到客户的信息后，开始下订单，扣款。</p>

<p><img src="media/15873033963371/15873054303125.jpg" alt="" style="width:576px;"/></p>

<h2 id="toc_10">二维码离线支付</h2>

<p>上文的方法有个弊端就是，如果客户端没有网络，就无法请求服务端生成二维码并支付了。这严重影响了用户的体验。</p>

<p>如果客户端可以自己生成uuid就好了。</p>

<ol>
<li>服务器生成token，通过加密方式（如https）传递到客户端。</li>
<li>打开付款码时，本地生成一段含有token和当前时间时间戳的哈希值，如sha1(token+UnixTimestamp),转换为byte[]并截取指定长度后转换为int变量otp。</li>
<li>设置支付用户账号（手机号）为int变量id。</li>
<li>设otp在[0, n]中，通过code=id*n+otp，即可将OTP和ID合并在同一个数字里，成为最终的二维码，并每隔指定时间更新一次。</li>
<li>通过商家扫码枪扫描，服务器获取了code，通过(int)(code/n)得到id，通过code%n得到otp。</li>
<li>通过id找到token，通过token和当前时间验证otp。</li>
<li>验证通过即可下单。</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[双因素认证（2FA）]]></title>
    <link href="http://565785929.github.io/15847222662823.html"/>
    <updated>2020-03-21T00:37:46+08:00</updated>
    <id>http://565785929.github.io/15847222662823.html</id>
    <content type="html"><![CDATA[
<p>一般情况下，网站登录都使用账号密码的方式登录，这是最常见的认证方法，但是不安全，容易泄露和冒充。</p>

<h2 id="toc_0">双因素认证概念：</h2>

<p>一般来说，三种不同类型的证据，可以证明一个人的身份。</p>

<ul>
<li>秘密信息：只有该用户知道、其他人不知道的某种信息，比如密码</li>
<li>个人物品：该用户的私人物品，比如身份证、钥匙、手机号</li>
<li>生物特征：该用户的遗传特征，比如指纹、相貌、虹膜等</li>
</ul>

<p>这些证据就称为三种”因素“。因素越多，证明力就越强，身份就越可靠。</p>

<p>双因素认证就是指，通过认证同事需要两个因素的证据。</p>

<p>银行卡取钱就是最常见的双因素认证。用户必须同时提供银行卡和密码，才能取到现金。</p>

<h2 id="toc_1">双因素认证方案</h2>

<p>常用的双因素组合是密码 + 某种个人物品，比如网上银行的 U 盾。用户插上 U 盾，再输入密码，才能登录网上银行。</p>

<p>但是，用户不可能随时携带 U 盾，手机才是最好的替代品。密码 + 手机就成了最佳的双因素认证方案。</p>

<p>国内的很多网站要求，用户输入密码时，还要提供短消息发送的验证码，以证明用户确实拥有该手机。</p>

<p>但是，短消息是不安全的，容易被拦截和伪造，SIM 卡也可以克隆。已经有案例，先伪造身份证，再申请一模一样的手机号码，把钱转走。</p>

<p>因此，安全的双因素认证不是密码 + 短消息，而是下面要介绍的 TOTP。</p>

<h2 id="toc_2">TOTP的概念</h2>

<p>TOTP 的全称是&quot;基于时间的一次性密码&quot;（Time-based One-time Password）。它是公认的可靠解决方案，已经写入国际标准 <a href="https://tools.ietf.org/html/rfc6238">RFC6238</a>。</p>

<p>它的步骤如下。</p>

<p>第一步，用户开启双因素认证后，服务器生成一个密钥。</p>

<p>第二步：服务器提示用户扫描二维码（或者使用其他方式），把密钥保存到用户的手机。也就是说，服务器和用户的手机，现在都有了同一把密钥。<br/>
<img src="media/15847222662823/15847227437312.jpg" alt=""/><br/>
注意，密钥必须跟手机绑定。一旦用户更换手机，就必须生成全新的密钥。</p>

<p>第三步，用户登录时，手机客户端使用这个密钥和当前时间戳，生成一个哈希，有效期默认为30秒。用户在有效期内，把这个哈希提交给服务器。<br/>
<img src="media/15847222662823/15847227654261.jpg" alt=""/><br/>
第四步，服务器也使用密钥和当前时间戳，生成一个哈希，跟用户提交的哈希比对。只要两者不一致，就拒绝登录。</p>

<h2 id="toc_3">TOTP算法</h2>

<p>仔细看上面的步骤，你可能会有一个问题：手机客户端和服务器，如何保证30秒期间都得到同一个哈希呢？</p>

<p>答案就是下面的公式。</p>

<p>TC = floor((unixtime(now) − unixtime(T0)) / TS)</p>

<p>上面的公式中，TC 表示一个时间计数器，unixtime(now)是当前 Unix 时间戳，unixtime(T0)是约定的起始时间点的时间戳，默认是0，也就是1970年1月1日。TS 则是哈希有效期的时间长度，默认是30秒。因此，上面的公式就变成下面的形式。</p>

<p>TC = floor(unixtime(now) / 30)<br/>
所以，只要在 30 秒以内，TC 的值都是一样的。前提是服务器和手机的时间必须同步。</p>

<p>接下来，就可以算出哈希了。</p>

<p>TOTP = HASH(SecretKey, TC)<br/>
上面代码中，HASH就是约定的哈希函数，默认是 SHA-1。</p>

<p>TOTP 有硬件生成器和软件生成器之分，都是采用上面的算法。</p>

<h2 id="toc_4">总结</h2>

<p>双因素认证的优点在于，比单纯的密码登录安全得多。就算密码泄露，只要手机还在，账户就是安全的。各种密码破解方法，都对双因素认证无效。</p>

<p>缺点在于，登录多了一步，费时且麻烦，用户会感到不耐烦。而且，它也不意味着账户的绝对安全，入侵者依然可以通过盗取 cookie 或 token，劫持整个对话（session）。</p>

<p>双因素认证还有一个最大的问题，那就是帐户的恢复。</p>

<p>一旦忘记密码或者遗失手机，想要恢复登录，势必就要绕过双因素认证，这就形成了一个安全漏洞。除非准备两套双因素认证，一套用来登录，另一套用来恢复账户。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux]]></title>
    <link href="http://565785929.github.io/15833368444152.html"/>
    <updated>2020-03-04T23:47:24+08:00</updated>
    <id>http://565785929.github.io/15833368444152.html</id>
    <content type="html"><![CDATA[
<p>Linux下的程序往往使你更加有效率，因为他们可以更高效的使用电脑的资源</p>

<p><strong>不同的Linux发行版之间的主要区别：</strong></p>

<p>1、安装方法不一样，有的复杂，有的简单。</p>

<p>2、安装应用程序的方式不一样。</p>

<p>3、预装的应用程序不一样。</p>

<h3 id="toc_0">linux发行版</h3>

<p>1、RedHat：性能稳定，老牌的linux发行版。收费的是RedHat Enterprise Linux（RHEL。redhat企业版）。目前RedHat分为两个系列：由RedHat公司提供收费技术支持。以及社区开发的免费的Fedora。</p>

<p>2、Fedora：RedHat的社区免费后继版，非常强大。</p>

<p>3、CentOS：国内许多企业选择CentOS，CentOS可以算是RHEL的克隆版，最大的好处就是免费。</p>

<p>4、SUSE：德国最著名的Linux发行版。</p>

<p>5、Debian：算是迄今为止，最遵循GNU规范的linux系统。（gnu的目标就是创建一套完全自由的操作系统。）</p>

<p>6、Ubuntu：Debian的后继一个分支。也是课程使用的linux发行版。</p>

<h3 id="toc_1">Ubuntu的优点</h3>

<p>1、简便易用。对于初学者，Ubuntu系统算是非常简单的，除了命令。</p>

<p>2、更新定期而频繁。每6个月就有一个新的Ubuntu版本，使用者非常多，支持的社区也很多。</p>

<p>3、标准化。</p>

<h3 id="toc_2">系统设置</h3>

<p><strong>lshw</strong>    获取硬件信息</p>

<p><strong>lscpu</strong>   获取CPU信息</p>

<p><strong>lsusb</strong>   获取usb接口信息</p>

<p><strong>uname</strong>   获取系统相关信息</p>

<p><strong>df</strong>  ：查看磁盘空间</p>

<p><strong>date</strong>    ：查看日期和时间</p>

<blockquote>
<p>&quot;+%j&quot; 今年中的第几天</p>
</blockquote>

<p><strong>hostname</strong>    ：显示主机名</p>

<p><strong>ifconfig</strong>    ：显示网络接口参数</p>

<h3 id="toc_3">关机重启命令</h3>

<p><strong>reboot</strong>  ：重启系统</p>

<p><strong>poweroff</strong>：   关机</p>

<p><strong>shutdown</strong>：   是定时关机</p>

<blockquote>
<p>shutdown -h time  指定时间，不写，就是一分钟之后执行</p>

<p>shutdown -h +5    ：五分钟后关机</p>

<p>shutdown -c   ：取消定时关机</p>

<p>shutdown -r now   ：立即重启</p>
</blockquote>

<h3 id="toc_4">常用指令</h3>

<pre class="line-numbers"><code class="language-python">#通过上下方向键来获取过往执行过的linux命令
#命令仅需输入前几位就可以用TAB键补全
要想准确，高效地完成各种任务，仅依赖命令本身是不够的，还应该根据实际情况来灵活调整各种命令的参数：
linux命令格式：
命令名称  [命令参数] [命令对象]
#命令名称、参数、对象之间用空格键分隔。

命令参数分为：
长格式  man --help
短格式  man -h

</code></pre>

<h3 id="toc_5">man 命令中常用按键以及用途</h3>

<table>
<thead>
<tr>
<th>按键</th>
<th>用处</th>
</tr>
</thead>

<tbody>
<tr>
<td>空格键</td>
<td>向下翻一页</td>
</tr>
<tr>
<td>page down</td>
<td>向下翻一页</td>
</tr>
<tr>
<td>page up</td>
<td>向上翻一页</td>
</tr>
<tr>
<td>home（fn+左方向键）</td>
<td>直接前往首页</td>
</tr>
<tr>
<td>end（fn+右方向键）</td>
<td>直接前往尾页</td>
</tr>
<tr>
<td>/</td>
<td>从上至下搜索某个关键词，如 ‘/and’</td>
</tr>
<tr>
<td>?</td>
<td>从下至上搜索某个关键词，如 ‘？and’</td>
</tr>
<tr>
<td>n</td>
<td>定位到下一个搜索到的关键词</td>
</tr>
<tr>
<td>N</td>
<td>定位到上一个搜索到的关键词</td>
</tr>
<tr>
<td>q</td>
<td>退出帮助文档</td>
</tr>
</tbody>
</table>

<h3 id="toc_6">目录命令</h3>

<p>1、pwd   ---print working directory</p>

<p>显示用户当前所处的工作目录</p>

<p>2、cd  ---change directory</p>

<p>用于切换工作路径</p>

<blockquote>
<p>cd 目录名  ：进入某一目录</p>

<p>cd ..    ：返回上一级目录，并显示路径</p>

<p>cd -   ：返回上一次所处的目录</p>

<p>cd ~     ：切换到当前用户的家目录</p>
</blockquote>

<p>3、ls ----list</p>

<p>ls会列举出当前工作目录的内容（文件或文件夹）</p>

<blockquote>
<p>-a    :查看所有文件（包括隐藏文件）</p>

<p>-l    ：查看文件的属性，大小等详细信息</p>
</blockquote>

<pre class="line-numbers"><code class="language-python">第一列一共十位：
#第一位是类型：
d代表目录
-代表是文件
l代表连接

#第二位到十位是权限
权限共九位，分三组，每三个一组
-rwx：
-r read 可读权限  4 或者 0
-w write 可写权限  2 或者 0  如果一条线，一个减号代表0
-x execute 可执行权限  1或者0

这三个字母能表示多少值:0-7
0：什么权限都没有
1：文件只能执行
2：文件只有写权限
3：文件可写可执行
4：文件只有读权限
5：可读可执行
6：可读可写
7：可读可写可执行

#对于文件而言：
可读权限表示允许读其内容，而禁止对其做任何的更改操作
可写权限表示可以改写编辑文件的内容或删除文件。（要有文件所在目录的写权限）
可执行权限表示允许将该文件作为一个程序执行。
#对于目录而言：
可读权限表示允许显示该目录中的内容
可写权限表示可以在目录中新建，删除，重名令文件
可执行权限表示可以进入该目录。可执行权限是基本权限。

权限共九位，每三个一组
1、代表当前用户的权限  ---读写和执行
2、代表当前用户所属的组的权限
3、代表其他组的权限

-w-


</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MyBatis 开启自动驼峰转换]]></title>
    <link href="http://565785929.github.io/15826152154212.html"/>
    <updated>2020-02-25T15:20:15+08:00</updated>
    <id>http://565785929.github.io/15826152154212.html</id>
    <content type="html"><![CDATA[
<p>在mybatis-config.xml文件中加入此设置</p>
<?xml version="1.0" encoding="UTF-8" ?>
<p>&lt;!DOCTYPE configuration<br/><br/>
PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;<br/><br/>
&quot;<a href="http://mybatis.org/dtd/mybatis-3-config.dtd%22%3E">http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;</a><br/><br/>
<configuration><br/><br/>
    <settings><br/><br/>
        <setting name="mapUnderscoreToCamelCase" value="true" /><br/><br/>
    </settings><br/><br/>
</configuration></p>

<p><img src="media/15826152154212/15826153307445.jpg" alt=""/></p>

<p>参考:<br/>
<a href="https://yq.aliyun.com/articles/662319">https://yq.aliyun.com/articles/662319</a><br/>
<a href="https://www.cnblogs.com/pjfmeng/p/7677773.html">https://www.cnblogs.com/pjfmeng/p/7677773.html</a><br/>
<a href="https://www.cnblogs.com/zhouricong/p/9483099.html">https://www.cnblogs.com/zhouricong/p/9483099.html</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[java和mysql转换]]></title>
    <link href="http://565785929.github.io/15823891714442.html"/>
    <updated>2020-02-23T00:32:51+08:00</updated>
    <id>http://565785929.github.io/15823891714442.html</id>
    <content type="html"><![CDATA[
<table>
<thead>
<tr>
<th>java类</th>
<th> </th>
<th>mysql数据库</th>
</tr>
</thead>

<tbody>
<tr>
<td>java.lang.Byte</td>
<td>byte</td>
<td>TINYINT</td>
</tr>
<tr>
<td>java.lang.Short</td>
<td>short</td>
<td>SMALLINT</td>
</tr>
<tr>
<td>java.lang.Integer</td>
<td>integer</td>
<td>INGEGER</td>
</tr>
<tr>
<td>java.lang.Long</td>
<td>long</td>
<td>BIGINT</td>
</tr>
<tr>
<td>java.lang.Float</td>
<td>float</td>
<td>FLOAT</td>
</tr>
<tr>
<td>java.lang.Double</td>
<td>double</td>
<td>DOUBLE</td>
</tr>
<tr>
<td>java.lang.BigDecimal</td>
<td>big_decimal</td>
<td>NUMERIC</td>
</tr>
<tr>
<td>java.lang.Boolean</td>
<td>boolean</td>
<td>BIT</td>
</tr>
<tr>
<td>java.lang.String</td>
<td>string</td>
<td>VARCHAR</td>
</tr>
<tr>
<td>java.lang.Boolean</td>
<td>yes_no</td>
<td>CHAR(1)(&#39;Y&#39;或&#39;N&#39;)</td>
</tr>
<tr>
<td>java.lang.Boolean</td>
<td>true_false</td>
<td>CHAR(1)(‘Y’或&#39;N&#39;)</td>
</tr>
<tr>
<td>java.uitl.Date</td>
<td>java.sql.Date</td>
<td>date</td>
</tr>
<tr>
<td>java.sql.Time</td>
<td>time</td>
<td>TIME</td>
</tr>
<tr>
<td>java.sql.Timestamp</td>
<td>timestamp</td>
<td>TIMESTAMP</td>
</tr>
<tr>
<td>java.uitl.Calendar</td>
<td>celendar</td>
<td>TIMESTAMP</td>
</tr>
<tr>
<td>java.uitl.Calendar</td>
<td>calendar</td>
<td>TIMESTAMP</td>
</tr>
<tr>
<td>java.io.Serializable</td>
<td>serializable</td>
<td>VARBINARY/BLOB</td>
</tr>
<tr>
<td>java.sql.Clob</td>
<td>clob</td>
<td>CLOB</td>
</tr>
<tr>
<td>java.sql.Blob</td>
<td>blob</td>
<td>BLOB</td>
</tr>
<tr>
<td>java.lang.Class</td>
<td>class</td>
<td>VARCHAR</td>
</tr>
<tr>
<td>java.uitl.Locale</td>
<td>locale</td>
<td>VARCHAR</td>
</tr>
<tr>
<td>java.uitl.TimeZone</td>
<td>timezone</td>
<td>VARCHAR</td>
</tr>
<tr>
<td>java.uitl.Currency</td>
<td>currency</td>
<td>VARCHAR</td>
</tr>
</tbody>
</table>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MySQL 查看表注释或字段注释]]></title>
    <link href="http://565785929.github.io/15823882245344.html"/>
    <updated>2020-02-23T00:17:04+08:00</updated>
    <id>http://565785929.github.io/15823882245344.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">查看注释</h2>

<p>查看所有表的注释</p>

<pre class="line-numbers"><code class="language-sql">SELECT
table_name 表名,
table_comment 表说明
FROM
information_schema.TABLES
WHERE
table_schema = &#39;数据库名&#39;
ORDER BY
table_name
</code></pre>

<p>查询所有表及字段的注释</p>

<pre class="line-numbers"><code class="language-sql">SELECT
a.table_name 表名,
a.table_comment 表说明,
b.COLUMN_NAME 字段名,
b.column_comment 字段说明,
b.column_type 字段类型,
b.column_key 约束
FROM
information_schema.TABLES a
LEFT JOIN information_schema.COLUMNS b ON a.table_name = b.TABLE_NAME
WHERE
a.table_schema = &#39;数据库名&#39;
ORDER BY
a.table_name
</code></pre>

<p>查询某表的所有字段的注释</p>

<pre class="line-numbers"><code class="language-sql">select 
COLUMN_NAME 字段名,
column_comment 字段说明,
column_type 字段类型,
column_key 约束 from information_schema.columns 
where table_schema = &#39;数据库名&#39;
and table_name = &#39;表名&#39; ; 
</code></pre>

<p>或者</p>

<pre class="line-numbers"><code class="language-sql">show full columns from 表名;
</code></pre>

<h2 id="toc_1">查看表生成的DDL</h2>

<p><strong>注意表名不加单引号</strong></p>

<pre class="line-numbers"><code class="language-sql">show create table 表名;
</code></pre>

<h2 id="toc_2">新建表以及添加表和字段的注释</h2>

<pre class="line-numbers"><code class="language-sql">create table t_user(
    ID INT(19) primary key auto_increment  comment &#39;主键&#39;,
    NAME VARCHAR(300) comment &#39;姓名&#39;,
    CREATE_TIME date comment &#39;创建时间&#39;
)comment  = &#39;用户信息表&#39;;
</code></pre>

<h2 id="toc_3">修改表/字段的注释</h2>

<p>修改表注释</p>

<pre class="line-numbers"><code class="language-sql">alter table t_user comment  = &#39;修改后的表注释信息(用户信息表)&#39;;
</code></pre>

<p>修改字段注释</p>

<pre class="line-numbers"><code class="language-sql">alter table t_user modify column id int comment &#39;主键ID&#39;;
</code></pre>

<p>参考：简书<a href="https://www.jianshu.com/p/e6286174d35c">Mysql 查看表注释或字段注释</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[网易云 最嗨电音 爬虫]]></title>
    <link href="http://565785929.github.io/15819525546014.html"/>
    <updated>2020-02-17T23:15:54+08:00</updated>
    <id>http://565785929.github.io/15819525546014.html</id>
    <content type="html"><![CDATA[
<p>抓手机包找到音乐链接 Size最大</p>

<p><img src="media/15819525546014/15819533512601.jpg" alt="" style="width:1062px;"/></p>

<p>贴到浏览器发现可以打开，确实为此音乐</p>

<p><img src="media/15819525546014/15819534156184.jpg" alt="" style="width:546px;"/></p>

<p>筛选所有音乐链接 <code>m\d.music.126.net</code><br/>
<img src="media/15819525546014/15819537374098.jpg" alt="" style="width:1152px;"/></p>

<p>积攒一段时间，将这些链接拷贝到文件里<br/>
<img src="media/15819525546014/15819535577751.jpg" alt="" style="width:973px;"/></p>

<p>编写Python代码，统一下载</p>

<pre class="line-numbers"><code class="language-python">import requests
from urllib import request


class Electronic:

    def __init__(self) -&gt; None:
        self.s = requests.session()
        self.dir = &quot;music/&quot;
        self.file = &quot;music.txt&quot;

    def open_file(self):
        with open(self.file, &#39;r&#39;) as f:
            for number, line in enumerate(f, start=1):
                yield line

    def get_music(self, url, name):
        try:
            self.s.get(url)
            request.urlretrieve(url, name)
        except Exception as ex:
            print(url, ex)

    def start(self):
        for url in self.open_file():
            print(url)
            name = url.split(&#39;/&#39;)[-1].strip()
            self.get_music(url, self.dir + name)


if __name__ == &#39;__main__&#39;:

    e = Electronic()
    e.start()

</code></pre>

]]></content>
  </entry>
  
</feed>
